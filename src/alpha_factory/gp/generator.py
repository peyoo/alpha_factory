"""
GP å› å­ç”Ÿæˆå™¨ä¸»ç±»

ä½¿ç”¨ DEAP åº“è¿›è¡Œé—ä¼ ç¼–ç¨‹ï¼Œè‡ªåŠ¨åŒ–å› å­æŒ–æ˜ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åŸºäºé—ä¼ ç¼–ç¨‹è‡ªåŠ¨ç”Ÿæˆå› å­è¡¨è¾¾å¼
2. æ‰¹é‡è®¡ç®—å’Œè¯„ä¼°å› å­é€‚åº”åº¦
3. æ”¯æŒè¿›åŒ–è¿‡ç¨‹çš„æ–­ç‚¹æ¢å¤
4. è‡ªåŠ¨ç¼“å­˜ä¸­é—´ç»“æœ

å…¸å‹ç”¨æ³•ï¼š
    config = {
        "split_date": datetime(2021, 1, 1),
        "batch_size": 50,
        "mu": 100,
        "lambda": 100,
        "hof_size": 100
    }
    generator = GPDeapGenerator(config)
    pop, logbook, hof = generator.run(input_data, n_gen=10, n_pop=500)
"""

import operator
import time
from datetime import datetime
from itertools import count
from pathlib import Path
from typing import Any, Dict, List, Tuple


import numpy as np
import polars as pl
from deap import base, creator, gp, tools
from deap.gp import PrimitiveTree
from expr_codegen.tool import ExprTool
from loguru import logger
import more_itertools

from alpha_factory.data_provider import DataProvider

# å¯¼å…¥æ‰“è¿‡è¡¥ä¸çš„ç»„ä»¶å’ŒåŸºç¡€å·¥å…·
from alpha_factory.gp.base import (
    population_to_exprs,
    filter_exprs,
    print_population,
    strings_to_sympy,
)
from alpha_factory.gp.base import RET_TYPE, Expr
from alpha_factory.gp.dependence import DependenceManager
from alpha_factory.gp.ea import eaMuPlusLambda_NSGA2
from alpha_factory.gp.label import label_OO_for_IC, label_OO_for_tradable
from alpha_factory.patch.deap_patch import apply_deap_patches
from alpha_factory.patch.expr_codegen_patch import apply_expr_codegen_patches
from alpha_factory.polars.utils import CUSTOM_OPERATORS
from alpha_factory.config.base import settings
from alpha_factory.utils.schema import F

from typing import TypeVar
from polars import DataFrame as _pl_DataFrame
from polars import LazyFrame as _pl_LazyFrame


DataFrame = TypeVar("DataFrame", _pl_LazyFrame, _pl_DataFrame)

# åœ¨è„šæœ¬æœ€ä¸Šæ–¹æˆ– __init__ ä¸­è°ƒç”¨ä¸€æ¬¡å³å¯
apply_expr_codegen_patches()
apply_deap_patches()


class GPDeapGenerator(object):
    """
    é—ä¼ ç¼–ç¨‹å› å­ç”Ÿæˆå™¨

    ä½¿ç”¨ DEAP æ¡†æ¶å®ç°çš„è‡ªåŠ¨åŒ–å› å­æŒ–æ˜å¼•æ“ã€‚

    Attributes:
        config (Dict): é…ç½®å‚æ•°å­—å…¸
        split_date (datetime): è®­ç»ƒ/æµ‹è¯•é›†åˆ†å‰²æ—¥æœŸ
        batch_size (int): æ‰¹é‡è®¡ç®—å¤§å°
        save_dir (Path): ç»“æœä¿å­˜ç›®å½•
        mu (int): ç§ç¾¤ä¿ç•™è§„æ¨¡
        lambda_ (int): æ¯ä»£ç”Ÿæˆåä»£è§„æ¨¡
        hof_size (int): åäººå ‚å¤§å°
    """

    def __init__(self, config: Dict[str, Any] = {}) -> None:
        """
        åˆå§‹åŒ– GP å› å­ç”Ÿæˆå™¨

        Args:
            config: é…ç½®å­—å…¸ï¼Œæ”¯æŒçš„é”®ï¼š
                - split_date (datetime): åˆ†å‰²æ—¥æœŸï¼Œè®­ç»ƒé›†äºéªŒè¯é›†çš„åˆ†å‰²æ—¥æœŸï¼Œé»˜è®¤None
                - batch_size (int): æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ 50
                - mu (int): è¿›åŒ–ç®—æ³•çš„ mu å‚æ•°ï¼Œé»˜è®¤ 100
                - lambda (int): è¿›åŒ–ç®—æ³•çš„ lambda å‚æ•°ï¼Œé»˜è®¤ 100
                - hof_size (int): åäººå ‚å¤§å°ï¼Œé»˜è®¤ 100

        Raises:
            ValueError: å¦‚æœé…ç½®å‚æ•°æ— æ•ˆ
        """
        # --- 1. åŸºç¡€ä¿¡æ¯é…ç½® ---
        self.config = config
        self.name = config.get("name", self.__class__.__name__)

        # --- 2. æ•°æ®ä¸æ—¥æœŸé…ç½® ---
        self.start_date = config.get("start_date", "20190101")
        self.end_date = config.get("end_date", "20241231")
        # åˆ†å‰²æ—¥æœŸï¼Œè®­ç»ƒé›†ä¸éªŒè¯é›†çš„åˆ†å‰²æ—¥æœŸï¼Œé»˜è®¤None
        self.split_date = config.get("split_date", None)
        # å¤šç›®æ ‡ä¼˜åŒ–åç§°åŠæƒé‡
        # è¿™é‡Œçš„åç§°è¦å’Œfitness_population_func è¾“å‡ºæŒ‡æ ‡ä¿æŒä¸€è‡´(è¦åŒ…å«å¯¹åº”çš„åˆ—)
        # complexityï¼Œè¡¨ç¤ºå› å­å¤æ‚åº¦ï¼Œå¯ä»¥ä¸åŒ…å«åœ¨fitness_population_funcè¾“å‡ºæŒ‡æ ‡ä¸­
        # independenceï¼Œè¡¨ç¤ºå› å­ç‹¬ç«‹æ€§åˆ†æ•°ï¼Œå¯ä»¥ä¸åŒ…å«åœ¨fitness_population_funcè¾“å‡ºæŒ‡æ ‡ä¸­
        # å¤šç›®æ ‡ç¤ºä¾‹
        # self.opt_names = config.get("opt_names",("ic_mean_abs", "ic_ir_abs",'complexity','independence'))  #
        # self.opt_weights = config.get("opt_weights",(1.0, 1.0,-0.01,1.0))  # å¤šç›®æ ‡ä¼˜åŒ–æƒé‡
        self.opt_names = config.get("opt_names", ("ic_mean_abs",))  #
        self.opt_weights = config.get("opt_weights", (1.0,))
        # æ•´ä½“ç§ç¾¤fitnesså‡½æ•°,
        # è¾“å…¥å‚æ•°ä¸º:df,factorsï¼ˆæ‰€æœ‰çš„å› å­åˆ—åï¼‰,split_date(å¯ä»¥æ²¡æœ‰ï¼Œè®­ç»ƒé›†ä¸éªŒè¯é›†çš„åˆ†å‰²æ—¥æœŸ),å…¶å®ƒå‚æ•°é‡‡ç”¨é»˜è®¤å€¼
        # è¾“å‡ºæ•°æ®æ ¼å¼ä¸º: pl.DataFrameï¼Œå¿…é¡»åŒ…å«åˆ—factor,ä»¥åŠopt_namesæ‰€åŒ…å«çš„åˆ—
        self.fitness_population_func = config.get("fitness_population_func", None)

        self.pool_func = config.get("pool_func", None)  # è‚¡ç¥¨æ± å‡½æ•°
        # æ ‡ç­¾è®¡ç®—å‡½æ•°ï¼Œæä¾›fitness_population_funcè®¡ç®—æ‰€éœ€çš„æ ‡ç­¾åˆ—ï¼Œ
        # ç”Ÿæˆçš„æ ‡ç­¾åˆ—åå¿…é¡»å’Œå‡½æ•°æ‰€éœ€åˆ—åä¸€è‡´ï¼Œä¸€èˆ¬ä¸º F.LABEL_FOR_IC å’Œ F.LABEL_FOR_RET
        self.label_funcs = config.get(
            "label_funcs", [label_OO_for_IC, label_OO_for_tradable]
        )
        self.extra_terminal_func = config.get(
            "extra_terminal_func", []
        )  # é¢å¤–ç»ˆç«¯å› å­è®¡ç®—å‡½æ•°

        self.terminals = config.get("terminals", [])  # ç»ˆç«¯å› å­åˆ—è¡¨
        self.random_window_func = config.get("random_window_func", None)  # éšæœºçª—å£å‡½æ•°

        # --- 4. è¿›åŒ–ç®—æ³•è¶…å‚æ•° ---
        self.mu = config.get("mu", 400)  # ç§ç¾¤ä¿ç•™è§„æ¨¡
        self.lambda_ = config.get("lambda", 400)  # æ¯ä»£ç”Ÿæˆåä»£è§„æ¨¡
        self.cxpb = config.get("cxpb", 0.3)  # äº¤å‰æ¦‚ç‡
        self.mutpb = config.get("mutpb", 0.5)  # å˜å¼‚æ¦‚ç‡
        self.hof_size = config.get("hof_size", 100)  # åäººå ‚å¤§å°
        self.batch_size = config.get("batch_size", 200)  # æ‰¹å¤„ç†å¤§å°
        self.max_height = config.get("max_height", 4)  # æœ€å¤§æ ‘é«˜é™åˆ¶
        # è·¯å¾„è®¾ç½®
        self._save_dir = None
        self.dep_manager = None  # å› å­ç‹¬ç«‹æ€§ç®¡ç†å™¨ï¼Œç¨ååˆå§‹åŒ–
        self.cluster_threshold = config.get(
            "cluster_threshold", 0.7
        )  # å› å­ç‹¬ç«‹æ€§èšç±»é˜ˆå€¼
        self.penalty_factor = config.get("penalty_factor", -0.1)  # å› å­ç‹¬ç«‹æ€§æƒ©ç½šå› å­

        self.seed_file = config.get(
            "seed_file", "best_factors.csv"
        )  # ç§å­æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæ–­ç‚¹æ¢å¤
        self.expression_formula = config.get(
            "expression_formula", "expression"
        )  # é¢„å®šä¹‰ç§å­å…¬å¼åˆ—è¡¨
        self.max_seed = config.get("max_seed", 0)  # æœ€å¤§ç§å­æ³¨å…¥æ•°é‡ï¼Œé»˜è®¤0ä¸æ³¨å…¥

        # ç¼“å­˜æœ¬è½®å®éªŒçš„é€‚åº”åº¦ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
        self.fitness_cache = {}

        logger.info(f"âœ“ GP ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ | æ‰¹å¤§å°: {self.batch_size}")

    @property
    def save_dir(self):
        """è·å–ç»“æœä¿å­˜ç›®å½•"""
        if self._save_dir is None:
            self._save_dir = Path(settings.OUTPUT_DIR) / self.pool_func.__name__
            self._save_dir.mkdir(parents=True, exist_ok=True)
        return self._save_dir

    def seep_file_path(self):
        """è·å–ç§å­æ–‡ä»¶è·¯å¾„"""
        return self.save_dir / self.seed_file

    def _build_pset(self) -> gp.PrimitiveSetTyped:
        """
        ç²¾ç®€ç‰ˆç®—å­é›†ï¼šä¸“ä¸º LightGBM/ElasticNet ç‰¹å¾å·¥ç¨‹è®¾è®¡
        æ‰€æœ‰ç®—å­å‡è¿”å›æ•°å€¼ç±»å‹ï¼Œç§»é™¤äº†å¯¼è‡´ SchemaError çš„é€»è¾‘ç®—å­
        """
        # ç›´æ¥ä½¿ç”¨ Expr ä½œä¸ºæ ‡è¯†ï¼Œé»˜è®¤å³ä¸ºæµ®ç‚¹æ•°åºåˆ—
        pset = gp.PrimitiveSetTyped("MAIN", [], Expr)
        return pset

    def build_toolbox(self, input_data: pl.LazyFrame) -> base.Toolbox:
        """
        æ„å»ºè¿›åŒ–å·¥å…·ç®±

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œç”¨äºé€‚åº”åº¦è¯„ä¼°

        Returns:
            base.Toolbox: DEAP å·¥å…·ç®±å®ä¾‹
        """
        creator.create("FitnessMulti", base.Fitness, weights=self.opt_weights)
        creator.create("Individual", PrimitiveTree, fitness=creator.FitnessMulti)

        toolbox = base.Toolbox()

        # æ ‘ç”Ÿæˆç®—æ³•: åŠæ•°åŠèŒæ³• (Half and Half)
        toolbox.register("expr", gp.genHalfAndHalf, pset=self.pset, min_=2, max_=3)
        toolbox.register(
            "individual", tools.initIterate, creator.Individual, toolbox.expr
        )
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)

        # é—ä¼ ç®—å­: é”¦æ ‡èµ›é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
        if len(self.opt_weights) == 1:
            toolbox.register(
                "select", tools.selTournament, tournsize=3
            )  # å•ç›®æ ‡ä¼˜åŒ–é€‰æ‹©
        else:
            toolbox.register("select", tools.selNSGA2)  # å¤šç›®æ ‡ä¼˜åŒ–é€‰æ‹©

        toolbox.register("mate", gp.cxOnePoint)
        toolbox.register("expr_mut", gp.genHalfAndHalf, min_=0, max_=3)
        toolbox.register("mutate", gp.mutUniform, expr=toolbox.expr_mut, pset=self.pset)

        # é™åˆ¶æ ‘é«˜ï¼Œé˜²æ­¢è†¨èƒ€ (Bloat)
        toolbox.decorate(
            "mate",
            gp.staticLimit(
                key=operator.attrgetter("height"), max_value=self.max_height
            ),
        )
        toolbox.decorate(
            "mutate",
            gp.staticLimit(
                key=operator.attrgetter("height"), max_value=self.max_height
            ),
        )

        # æ ¸å¿ƒï¼šæ‰¹é‡è¯„ä¼°æ˜ å°„
        toolbox.register(
            "evaluate", lambda x: (np.nan, np.nan)
        )  # å®é™…è¯„åˆ†åœ¨ map ä¸­å®Œæˆ
        toolbox.register(
            "map",
            self.map_exprs,
            gen=count(),
            split_date=self.split_date,
            input_data=input_data,
        )

        logger.debug("âœ“ Toolbox æ„å»ºå®Œæˆ")
        return toolbox

    def _extra_toolbox_settings(self, toolbox):
        """é¢å¤–çš„ Toolbox è®¾ç½®ï¼ˆå¯é€‰æ‰©å±•ï¼‰,ä¼šè¦†ç›–é»˜è®¤çš„è®¾ç½®"""
        pass

    def build_statistics(self) -> tools.Statistics:
        """
        å®šä¹‰è¿›åŒ–è¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ç›‘æ§æŒ‡æ ‡

        Returns:
            tools.Statistics: DEAP ç»Ÿè®¡å¯¹è±¡
        """
        stats = tools.Statistics(lambda ind: ind.fitness.values)
        stats.register("avg", np.nanmean, axis=0)
        stats.register("max", np.nanmax, axis=0)
        stats.register("min", np.nanmin, axis=0)
        stats.register("std", np.nanstd, axis=0)
        return stats

    def seed_load(self, pop, seed_exprs: List[str], max_seeds: int = 20) -> List:
        """
        å°†é¢„å®šä¹‰çš„ç§å­å…¬å¼æ³¨å…¥ç§ç¾¤ã€‚å»æ‰äº†èšç±»é€»è¾‘ï¼Œç›´æ¥è¿›è¡Œå¼ºç±»å‹è½¬æ¢ã€‚

        Args:
            pop: åˆå§‹åŒ–çš„ DEAP ç§ç¾¤åˆ—è¡¨
            seed_exprs: å€™é€‰å…¬å¼å­—ç¬¦ä¸²åˆ—è¡¨
            max_seeds: æœ€å¤§æ³¨å…¥æ•°é‡

        Returns:
            pop: æ³¨å…¥ç§å­åçš„ç§ç¾¤
        """
        if not seed_exprs:
            return pop

        logger.info(f"ğŸŒ± æ­£åœ¨åŠ è½½ç§å­é€‰æ‰‹ (ä¸Šé™: {max_seeds})...")

        # 1. é™åˆ¶ç§å­æ•°é‡ï¼Œé˜²æ­¢å…¶å®Œå…¨å æ®åˆå§‹ç§ç¾¤
        actual_seeds_to_load = seed_exprs[:max_seeds]

        # 2. åˆ©ç”¨ Sympy è¿›è¡Œé¢„å¤„ç†ï¼ˆä¸»è¦ä¸ºäº†æ ¼å¼è§„èŒƒåŒ–å’Œç®€åŒ–ï¼‰
        try:
            # strings_to_sympy è¿”å› [(name, expr_obj, complexity), ...]
            processed = strings_to_sympy(actual_seeds_to_load, globals().copy())
        except Exception as e:
            logger.error(f"âŒ Sympy é¢„å¤„ç†ç§å­å¤±è´¥: {e}")
            return pop

        seeds_count = 0
        for i, (name, expr_obj, _) in enumerate(processed):
            if i >= len(pop):
                break

            try:
                # 3. å°† Sympy è¡¨è¾¾å¼è½¬å›å­—ç¬¦ä¸²å¹¶å¤„ç†æ½œåœ¨çš„ç±»å‹ä¸åŒ¹é…
                # é’ˆå¯¹ PrimitiveSetTyped çš„å¸¸è§é—®é¢˜ï¼šå°† "20.0" æ›¿æ¢å› "20"
                expr_str = str(expr_obj).replace(".0)", ")").replace(".0,", ",")

                # 4. å¼ºç±»å‹è½¬æ¢å¹¶æ›¿æ¢ç§ç¾¤ä¸­çš„ä¸ªä½“
                ind = creator.Individual.from_string(expr_str, self.pset)
                pop[i] = ind
                seeds_count += 1
                logger.debug(f"âœ… ç§å­æ³¨å…¥æˆåŠŸ [{seeds_count}]: {expr_str}")

            except Exception as e:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼ˆé€šå¸¸æ˜¯ç®—å­åä¸åŒ¹é…æˆ–å‚æ•°ç±»å‹ä¸å¯¹ï¼‰ï¼Œè·³è¿‡è¯¥ç§å­
                logger.warning(f"âš ï¸ ç§å­è½¬æ¢è·³è¿‡: {expr_obj} | é”™è¯¯: {e}")
                continue

        logger.success(f"âœ¨ ç§å­æ³¨å…¥æµç¨‹ç»“æŸï¼ŒæˆåŠŸæ³¨å…¥ {seeds_count} ä¸ªä¸ªä½“")
        return pop

    def run(
        self, n_gen: int = 10, n_pop: int = 1000
    ) -> Tuple[List, Any, tools.HallOfFame]:
        """
        å¯åŠ¨è¿›åŒ–æµç¨‹

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œå¿…é¡»åŒ…å«æ ‡ç­¾åˆ—
            n_gen: è¿›åŒ–ä»£æ•°ï¼Œé»˜è®¤ 10
            n_pop: åˆå§‹ç§ç¾¤å¤§å°ï¼Œé»˜è®¤ 1000

        Returns:
            Tuple: (æœ€ç»ˆç§ç¾¤, è¿›åŒ–æ—¥å¿—, åäººå ‚)

        Raises:
            ValueError: å¦‚æœè¾“å…¥æ•°æ®æ— æ•ˆ
        """
        # åˆå§‹åŒ–ç®¡ç†å™¨, ç”¨äºå› å­ç‹¬ç«‹æ€§è¯„ä¼°
        self.dep_manager = DependenceManager(
            opt_names=self.opt_names,
            opt_weights=self.opt_weights,
            cluster_threshold=self.cluster_threshold,
            penalty_factor=self.penalty_factor,
        )

        # 2. è½½å…¥åŸå§‹æ•°æ®
        # æŒ–æ˜å› å­é€šå¸¸éœ€è¦ OHLCVï¼Œè®¡ç®— OO æ”¶ç›Šç‡éœ€è¦ OPEN
        input_data = DataProvider().load_data(
            start_date=self.start_date,
            end_date=self.end_date,
            funcs=[self.pool_func, *self.label_funcs, self.extra_terminal_func],
            select_cols=[F.POOL_MASK, F.LABEL_FOR_IC, F.LABEL_FOR_RET, *self.terminals],
            cache_path=self.save_dir / f"{self.pool_func.__name__}.parquet",
        )
        logger.info("ğŸ’¾ æ ‡ç­¾æ•°æ®å·²å°±ç»ª")

        logger.info(f"ğŸš€ å¯åŠ¨ GP è¿›åŒ– | ä»£æ•°: {n_gen} | ç§ç¾¤: {n_pop}")
        self.pset = self._build_pset()
        toolbox = self.build_toolbox(input_data)
        stats = self.build_statistics()
        if len(self.opt_weights) == 1:
            # å•ç›®æ ‡ selTournament
            hof = tools.HallOfFame(
                self.hof_size, similar=lambda ind1, ind2: str(ind1) == str(ind2)
            )
        else:
            # å¤šç›®æ ‡ selNSGA2
            hof = tools.ParetoFront(similar=lambda ind1, ind2: str(ind1) == str(ind2))

        # åˆå§‹åŒ–ç§ç¾¤
        pop = toolbox.population(n=n_pop)
        logger.info(f"âœ“ åˆå§‹ç§ç¾¤å·²ç”Ÿæˆ | å¤§å°: {len(pop)}")

        if self.seep_file_path().exists() and self.max_seed > 0:
            try:
                seed_df = pl.read_csv(self.seep_file_path())
                seed_exprs = seed_df[self.expression_formula].to_list()
                pop = self.seed_load(pop, seed_exprs, self.max_seed)
            except Exception as e:
                logger.error(f"âŒ ç§å­æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

        # æ‰§è¡Œè¿›åŒ–
        logger.info("â–¶ï¸ å¼€å§‹é—ä¼ ç¼–ç¨‹è¿›åŒ–...")
        pop, logbook = eaMuPlusLambda_NSGA2(
            pop,
            toolbox,
            mu=self.mu,
            lambda_=self.lambda_,
            cxpb=self.cxpb,  # äº¤å‰æ¦‚ç‡
            mutpb=self.mutpb,  # å˜å¼‚æ¦‚ç‡
            ngen=n_gen,
            stats=stats,
            halloffame=hof,
            verbose=True,
            generator=self,
        )

        logger.info(f"âœ¨ GP è¿›åŒ–å®Œæˆ | æœ€ç»ˆç§ç¾¤: {len(pop)} | åäººå ‚: {len(hof)}")

        print("=" * 60)
        print(logbook)

        print("=" * 60)
        print_population(hof, globals().copy())
        self.export_hof_to_csv(hof, globals().copy())
        return pop, logbook, hof

    def map_exprs(
        self,
        evaluate_func: Any,
        individuals: List,
        gen,
        split_date: datetime,
        input_data: pl.DataFrame,
    ) -> List[Tuple]:
        """
        æ‰¹é‡è®¡ç®—ç§ç¾¤é€‚åº”åº¦çš„æ ¸å¿ƒæ–¹æ³•

        å¤„ç†æµç¨‹ï¼š
        1. å¤‡ä»½å½“å‰ä»£çš„è¡¨è¾¾å¼
        2. åŠ è½½å†å²é€‚åº”åº¦ç¼“å­˜
        3. æå–å¹¶è¿‡æ»¤è¡¨è¾¾å¼
        4. æ‰¹é‡è®¡ç®—æ–°è¡¨è¾¾å¼çš„é€‚åº”åº¦
        5. æ›´æ–°ç¼“å­˜å¹¶è¿”å›ç»“æœ

        Args:
            evaluate_func: è¯„ä¼°å‡½æ•°ï¼ˆæœªä½¿ç”¨ï¼Œç”± map è°ƒç”¨è¦æ±‚ï¼‰
            individuals: å½“å‰ä»£çš„ä¸ªä½“åˆ—è¡¨
            gen: ä»£æ•°è¿­ä»£å™¨
            split_date: è®­ç»ƒ/æµ‹è¯•åˆ†å‰²æ—¥æœŸ
            input_data: è¾“å…¥æ•°æ®

        Returns:
            List[Tuple]: æ¯ä¸ªä¸ªä½“çš„é€‚åº”åº¦å…ƒç»„åˆ—è¡¨
        """
        g = next(gen)
        logger.info(f">>> ç¬¬ {g} ä»£ | ç§ç¾¤å¤§å°: {len(individuals)}")

        # 3. è¡¨è¾¾å¼æ¸…æ´—ä¸è¿‡æ»¤
        logger.debug("ğŸ”„ è½¬æ¢ DEAP æ ‘ -> Sympy è¡¨è¾¾å¼...")
        exprs_list = population_to_exprs(individuals, globals().copy())
        exprs_to_calc = filter_exprs(
            exprs_list, self.pset, RET_TYPE, self.fitness_cache
        )

        logger.info(f"ğŸ“Š éœ€è®¡ç®—: {len(exprs_to_calc)} / {len(exprs_list)} ä¸ªè¡¨è¾¾å¼")

        # 4. æ‰¹é‡è®¡ç®—
        if len(exprs_to_calc) > 0:
            for batch_id, batch in enumerate(
                more_itertools.batched(exprs_to_calc, self.batch_size)
            ):
                logger.debug(f"  æ‰¹æ¬¡ {batch_id + 1} | å¤§å°: {len(list(batch))}")
                new_scores = self.batched_exprs(
                    batch_id, list(batch), g, split_date, input_data
                )
                self.fitness_cache.update(new_scores)

        # 5. å›å¡«é€‚åº”åº¦ï¼ˆå¯åŠ å…¥æƒ©ç½šï¼‰
        fitness_values = self.fill_fitness(individuals, exprs_list, self.fitness_cache)
        logger.info(f"âœ“ ç¬¬ {g} ä»£è¯„ä¼°å®Œæˆ")
        return fitness_values

    def _calc_exprs(self, exprs_list, df_input):
        lf = df_input.lazy() if isinstance(df_input, pl.DataFrame) else df_input

        tool = ExprTool()
        codes, G = tool.all(
            exprs_list,
            style="polars",
            template_file="template.py.j2",
            replace=False,
            regroup=True,
            format=True,
            date="DATE",
            asset="ASSET",
            over_null=None,
            skip_simplify=True,
        )

        globals_ = {**CUSTOM_OPERATORS}
        exec(codes, globals_)

        df_output = globals_["main"](lf, ge_date_idx=0).collect()

        return df_output

    def batched_exprs(self, batch_id, exprs_list, gen, split_date, df_input):
        """æ¯ä»£ç§ç¾¤åˆ†æ‰¹è®¡ç®—ï¼ŒåŒ…å«è¯¦ç»†æ€§èƒ½æ—¥å¿—åŠå¹³å‡ç”¨æ—¶"""
        if len(exprs_list) == 0:
            return {}

        # --- é˜¶æ®µ A: å› å­å€¼è®¡ç®— ---
        cnt = len(exprs_list)
        logger.info("ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šå¼€å§‹è®¡ç®—å› å­å€¼ (å…± {} æ¡)", gen, batch_id, cnt)
        tic_calc = time.perf_counter()

        df_output = self._calc_exprs(exprs_list, df_input)

        toc_calc = time.perf_counter()
        calc_duration = toc_calc - tic_calc

        # æ—¥å¿—è¾“å‡ºï¼šæ·»åŠ é€Ÿåº¦å’Œå¹³å‡è€—æ—¶
        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šè®¡ç®—å®Œæˆã€‚æ€»è€—æ—¶: {:.3f}s | é€Ÿåº¦: {:.2f} æ¡/s | å¹³å‡: {:.4f}s/æ¡",
            gen,
            batch_id,
            calc_duration,
            cnt / calc_duration,
            calc_duration / cnt,
        )

        # --- é˜¶æ®µ B: é€‚åº”åº¦è®¡ç®— ---
        logger.info("ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šå¼€å§‹èšåˆè®¡ç®— IC/RET é€‚åº”åº¦æŒ‡æ ‡", gen, batch_id)
        tic_fit = time.perf_counter()

        factor_columns = [k for k, v, c in exprs_list]
        import inspect

        if (
            split_date
            and "split_date"
            in inspect.signature(self.fitness_population_func).parameters
        ):
            fitness_df = self.fitness_population_func(
                df_output, factors=factor_columns, split_date=split_date
            )
        else:
            fitness_df = self.fitness_population_func(df_output, factors=factor_columns)

        toc_fit = time.perf_counter()
        fit_duration = toc_fit - tic_fit

        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šèšåˆå®Œæˆã€‚è€—æ—¶: {:.3f}s | å¹³å‡: {:.4f}s/æ¡",
            gen,
            batch_id,
            fit_duration,
            fit_duration / cnt,
        )

        # 3. ç»“æœè½¬æ¢
        key_to_expr = {k: str(v) for k, v, c in exprs_list}
        new_results = {}
        for row in fitness_df.to_dicts():
            f_name = row.pop("factor")
            # è·å–å¯¹åº”çš„è¡¨è¾¾å¼å­—ç¬¦ä¸²ä½œä¸º Key
            expr_str = key_to_expr[f_name]
            new_results[expr_str] = row

        if "independence" in self.opt_names:
            # è¿™é‡Œçš„ exprs_list åŒ…å«äº† (å› å­å, è¡¨è¾¾å¼å¯¹è±¡, _)
            self.dep_manager.register_fingerprints(df_output, exprs_list)

        # 4. æ±‡æ€»
        total_dur = calc_duration + fit_duration
        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šæµç¨‹ç»“æŸã€‚æ€»è®¡: {:.3f}s | æ€»å¹³å‡: {:.4f}s/æ¡ (ç®—å€¼:{:.1%}, æŒ‡æ ‡:{:.1%})",
            gen,
            batch_id,
            total_dur,
            total_dur / cnt,
            calc_duration / total_dur,
            fit_duration / total_dur,
        )

        return new_results

    def fill_fitness(self, individuals, exprs_old, fitness_results):
        """
        é‡æ„ç‰ˆï¼šå®Œå…¨é€‚é…æŒ‰ä½ç½®è¯„åˆ†çš„ç‹¬ç«‹æ€§æ¥å£
        """
        if len(individuals) != len(exprs_old):
            raise ValueError(
                f"æ•°æ®å¯¹é½å¤±è´¥: individuals({len(individuals)}) != exprs_old({len(exprs_old)})"
            )

        # 1. é¢„è®¡ç®—æƒ©ç½šå‘é‡
        penalty_values = tuple(0.0 if w > 0 else 999.0 for w in self.opt_weights)

        # 2. æŒ‚è½½ expr_str å¹¶æ”¶é›†å…¨é‡è¡¨è¾¾å¼
        all_expr_strs = []
        for ind, (_, v, _) in zip(individuals, exprs_old):
            search_key = str(v)
            ind.expr_str = search_key  # æ–¹ä¾¿åç»­ update_and_prune è¯†åˆ«
            all_expr_strs.append(search_key)

        # 3. ã€æ ¸å¿ƒä¿®æ”¹ã€‘è·å–æŒ‰ä½ç½®å¯¹åº”çš„ç‹¬ç«‹æ€§åˆ†æ•°åˆ—è¡¨
        # ç°åœ¨çš„ indep_scores_list æ˜¯ä¸€ä¸ª List[float]ï¼Œé•¿åº¦ä¸ individuals ä¸€è‡´
        indep_scores_list = self.dep_manager.calculate_contextual_independence(
            all_expr_strs, fitness_results
        )

        fit_tuples_list = []

        # 4. éå†å¡«å……ï¼šåˆ©ç”¨ zip(individuals, all_expr_strs, indep_scores_list) å®ç°ç‰©ç†å¯¹é½
        for ind, search_key, current_indep_score in zip(
            individuals, all_expr_strs, indep_scores_list
        ):
            score_dict = fitness_results.get(search_key)

            # æƒ…å†µ A: åŒ¹é…å¤±è´¥æˆ–è§¦å‘æƒ©ç½š
            if score_dict is None or self.is_penalty(score_dict):
                fit_tuples_list.append(penalty_values)
                ind.stats = None
                continue

            # æƒ…å†µ B: æ­£å¸¸è¯„ä¼°
            try:
                current_fit = []
                for i, name in enumerate(self.opt_names):
                    # é€»è¾‘åˆ†æ”¯ 1: å¤æ‚åº¦ (é™æ€)
                    if name == "complexity":
                        val = float(len(ind))

                    # é€»è¾‘åˆ†æ”¯ 2: ç‹¬ç«‹æ€§ (ä½¿ç”¨ DM å®æ—¶è®¡ç®—çš„ã€åŸºäºä½ç½®çš„åˆ†æ•°)
                    elif name == "independence":
                        # ã€å…³é”®ç‚¹ã€‘è¿™é‡Œä¸å†æŸ¥è¡¨ï¼Œç›´æ¥ç”¨ current_indep_score
                        val = float(current_indep_score)

                    # é€»è¾‘åˆ†æ”¯ 3: å…¶ä»–ç»©æ•ˆæŒ‡æ ‡
                    else:
                        raw_val = score_dict.get(name)
                        if raw_val is None or not np.isfinite(raw_val):
                            val = penalty_values[i]
                        else:
                            val = float(raw_val)

                    current_fit.append(val)

                fit_tuple = tuple(current_fit)
                fit_tuples_list.append(fit_tuple)

                # æ›´æ–° statsï¼Œç¡®ä¿ stats é‡Œçš„ç‹¬ç«‹æ€§ä¹Ÿæ˜¯â€œè¿™ä¸ªä¸ªä½“â€ä¸“å±çš„å®æ—¶åˆ†æ•°
                final_stats = score_dict.copy()
                if "independence" in self.opt_names:
                    final_stats["independence"] = current_indep_score
                ind.stats = final_stats

            except Exception as e:
                logger.error(f"å¤„ç†é€‚åº”åº¦å¼‚å¸¸: {e} | {search_key}")
                fit_tuples_list.append(penalty_values)
                ind.stats = None

        return fit_tuples_list

    def is_penalty(self, score_dict):
        """åˆ¤æ–­æŸä¸ªè®¡ç®—ç»“æœæ˜¯å¦ä¸ºæƒ©ç½šå€¼"""
        if "ic_ir" in score_dict:
            val = score_dict["ic_ir"]
            if np.isnan(val) or val < 0.0001:
                return True
        return False

    def export_hof_to_csv(self, hof, globals_, filename="gp_best_factors.csv"):
        """
        å°†åäººå ‚å†…å®¹å¯¼å‡ºåˆ° CSV

        Args:
            hof: åäººå ‚å¯¹è±¡
            globals_: å…¨å±€å‘½åç©ºé—´ globals()
            filename: è¾“å‡ºæ–‡ä»¶å
        """
        import pandas as pd

        # exprs_list å¾—åˆ°çš„æ˜¯ (ç®€åŒ–å k, è¡¨è¾¾å¼æ–‡æœ¬ v, å¤æ‚åº¦ c)
        exprs_list = population_to_exprs(hof, globals_)
        data = []
        for (k, v, c), ind in zip(exprs_list, hof):
            kvs = {
                "factor_name": k,  # å› å­ç®€åŒ–å
                "expression": v,  # ç®€åŒ–åçš„è¡¨è¾¾å¼æ–‡æœ¬ (v)
                "complexity": c,  # å¤æ‚åº¦ (c)
                "raw_tree": str(ind),  # åŸå§‹ DEAP æ ‘ç»“æ„
            }
            # æå–åäººå ‚ä¸ªä½“çš„é€‚åº”åº¦å€¼å¹¶å­˜å‚¨åˆ°å­—å…¸ä¸­
            for name, value in zip(self.opt_names, ind.fitness.values):
                kvs[name] = value
            data.append(kvs)

        # 2. è½¬æ¢ä¸º DataFrame å¹¶ä¿å­˜
        df = pd.DataFrame(data)
        output_path = self.save_dir / filename
        df.to_csv(output_path, index=False, encoding="utf-8-sig")
        logger.info(f"âœ… åäººå ‚å› å­å·²å¯¼å‡ºè‡³ CSV: {output_path}")
        return df
