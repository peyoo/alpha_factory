import threading
import pandas as pd
import polars as pl
import gc
from pathlib import Path
from loguru import logger
from typing import Optional, List, Union
from datetime import date


class HDF5CacheManager:
    """
    HDF5 é«˜æ€§èƒ½çƒ­ç¼“å­˜ç®¡ç†å™¨ (L1 å±‚)

    ã€æ ¸å¿ƒæ”¹è¿›ã€‘
    - çº¿ç¨‹å®‰å…¨ï¼šæ‰€æœ‰å¥æŸ„æ“ä½œå‡ç”± threading.Lock ä¿æŠ¤ã€‚
    - å†…å­˜å‹å¥½ï¼šload_as_polars é‡‡ç”¨åˆ†ç‰‡è½¬æ¢æ¨¡å¼ï¼Œé™ä½å†…å­˜å³°å€¼ã€‚
    - å½»åº•é‡Šæ”¾ï¼šclose_all é‡‡ç”¨ pop æ¨¡å¼åˆ‡æ–­å¼•ç”¨ï¼Œå¼ºåˆ¶ gc å›æ”¶ã€‚
    """

    def __init__(self, cache_dir: Path):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._stores: dict[str, pd.HDFStore] = {}
        # ğŸ’¡ åˆå§‹åŒ–é”ï¼Œç¡®ä¿å¤šçº¿ç¨‹ä¸‹å¥æŸ„åˆ›å»ºçš„å®‰å…¨
        self._lock = threading.Lock()

    def close_all(self):
        """å®‰å…¨å…³é—­æ‰€æœ‰æ‰“å¼€çš„ HDF5 æ–‡ä»¶å¥æŸ„å¹¶å½»åº•é‡Šæ”¾å†…å­˜"""
        with self._lock:
            # ä½¿ç”¨ list() é¿å…åœ¨è¿­ä»£æ—¶å› å­—å…¸ä¿®æ”¹ï¼ˆpopï¼‰å¯¼è‡´æŠ¥é”™
            keys = list(self._stores.keys())
            for key in keys:
                store = self._stores.pop(key)  # ğŸ’¡ å…³é”®ï¼špop å¼¹å‡ºå¼•ç”¨
                if store is not None:
                    try:
                        # åªæœ‰å¥æŸ„å¤„äºæ‰“å¼€çŠ¶æ€æ‰æ‰§è¡Œå…³é—­
                        if store.is_open:
                            store.close()
                        logger.debug(f"ğŸ”’ HDF5 æ–‡ä»¶å·²å®‰å…¨å…³é—­: {key}")
                    except Exception as e:
                        logger.error(f"å…³é—­ {key} å¤±è´¥: {e}")

        # ğŸ’¡ å¼ºåˆ¶è§¦å‘åƒåœ¾å›æ”¶ï¼Œé…åˆ pop åˆ‡æ–­å¼•ç”¨é“¾
        gc.collect()

    def _get_store(self, source: str) -> pd.HDFStore:
        """è·å–æˆ–åˆ›å»º HDFStore å¥æŸ„ (çº¿ç¨‹å®‰å…¨)"""
        with self._lock:
            if source not in self._stores or not self._stores[source].is_open:
                path = self.cache_dir / f"{source}.h5"
                # ä½¿ç”¨ blosc å‹ç¼©ï¼Œè¿™æ˜¯é‡åŒ–åœºæ™¯ä¸‹é€Ÿåº¦ä¸ä½“ç§¯çš„æœ€ä½³å¹³è¡¡
                self._stores[source] = pd.HDFStore(
                    path, mode="a", complevel=4, complib="blosc"
                )
            return self._stores[source]

    def is_cached(self, source: str, trade_date: Union[str, date]) -> bool:
        """æ£€æŸ¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®æ˜¯å¦å­˜åœ¨äºç¼“å­˜ä¸­"""
        date_str = (
            trade_date if isinstance(trade_date, str) else trade_date.strftime("%Y%m%d")
        )
        key = f"/{source}_{date_str}"

        cache_file = self.cache_dir / f"{source}.h5"
        if not cache_file.exists():
            return False

        try:
            store = self._get_store(source)
            return key in store
        except Exception as e:
            logger.debug(f"æ£€æŸ¥ç¼“å­˜å¤±è´¥ ({source}_{date_str}): {e}")
            return False

    def save_to_hdf5(
        self, source: str, trade_date: Union[str, date], df: pd.DataFrame
    ) -> None:
        if df is None or df.empty:
            return

        # ğŸ’¡ é¢å¤–çš„ä¸€æ­¥ï¼šç¡®ä¿ ts_code å­˜å‚¨ä¸ºå›ºå®šé•¿åº¦å­—èŠ‚ä¸²
        # è¿™è®© HDF5 çš„ Fixed æ¨¡å¼è¿è¡Œæ•ˆç‡æœ€é«˜
        if "ts_code" in df.columns:
            df = df.copy()  # é¿å…ä¿®æ”¹åŸå§‹è¾“å…¥
            df["ts_code"] = df["ts_code"].astype(str).astype("S12")

        date_str = (
            trade_date if isinstance(trade_date, str) else trade_date.strftime("%Y%m%d")
        )
        key = f"{source}_{date_str}"

        self._get_store(source).put(key, df, format="fixed")
        logger.debug(f"âœ“ [Fixed-NoDate] ç¼“å­˜å†™å…¥: {key}")

    def load_as_polars(
        self, source: str, trading_dates: List[date]
    ) -> Optional[pl.DataFrame]:
        """
        [æé€Ÿå‡ºå£] æ‰¹é‡åŠ è½½å¹¶é‡æ„æ•°æ®
        é€»è¾‘ï¼šä» HDF5 è¯»å–åŸå§‹æ•°æ® -> ä¿®å¤ Binary ç±»å‹ -> é‡å‘½å ts_code -> å›å¡« DATE -> å‚ç›´åˆå¹¶
        """
        if not trading_dates:
            return None

        store = self._get_store(source)
        # è·å–å½“å‰ Store ä¸­æ‰€æœ‰çš„ Keyï¼Œä½¿ç”¨ set åŠ é€ŸæŸ¥è¯¢
        available_keys = set(store.keys())

        pldfs = []
        for d in trading_dates:
            date_str = d.strftime("%Y%m%d")
            key = f"/{source}_{date_str}"

            if key in available_keys:
                # 1. ä» HDF5 è¯»å– Pandas (æ­¤æ—¶ä¸å«æ—¥æœŸåˆ—ï¼Œts_code ä¸º bytes)
                pdf = store[key]
                if pdf.empty:
                    continue

                # 2. è½¬æ¢ä¸º Polars
                pldf = pl.from_pandas(pdf)

                # 3. ğŸ’¡ ç±»å‹ä¿®å¤ï¼šå¤„ç† Binary -> String è½¬æ¢
                # HDF5 ä»¥ S12 å­˜å‚¨ä¼šå¯¼è‡´ Polars è¯†åˆ«ä¸º Binaryï¼Œå¿…é¡»è½¬å› String æ‰èƒ½è¿›è¡Œ is_in è¿‡æ»¤
                binary_cols = [
                    col for col, dtype in pldf.schema.items() if dtype == pl.Binary
                ]
                if binary_cols:
                    pldf = pldf.with_columns(
                        [pl.col(c).cast(pl.String) for c in binary_cols]
                    )

                # 4. æ•°å€¼ç²¾åº¦å¯¹é½ï¼šå¼ºåˆ¶è½¬æ¢æ•°å€¼åˆ—ç±»å‹ï¼Œé˜²æ­¢ concat æ—¶çš„ schema ä¸åŒ¹é…
                for col in pldf.columns:
                    if col in ["ts_code", "ASSET"]:
                        continue
                    # å°†æ‰€æœ‰ float64 ç»Ÿä¸€ä¸º float32 (é™¤éæ˜¯éœ€è¦é«˜ç²¾åº¦çš„æˆäº¤é¢æˆ–å¸‚å€¼)
                    if pldf.schema[col] == pl.Float64 and col not in [
                        "amount",
                        "total_mv",
                    ]:
                        pldf = pldf.with_columns(pl.col(col).cast(pl.Float32))

                # 5. å­—æ®µæ ‡å‡†åŒ–ï¼šts_code -> ASSET
                if "ts_code" in pldf.columns:
                    pldf = pldf.rename({"ts_code": "ASSET"})

                # 6. ğŸ’¡ æ ¸å¿ƒé€»è¾‘ï¼šåˆ©ç”¨ Polars çš„å¹¿æ’­æœºåˆ¶å›å¡«æ—¥æœŸ
                pldf = pldf.with_columns(pl.lit(d).alias("DATE"))

                pldfs.append(pldf)

        if not pldfs:
            logger.warning(f"âš ï¸ ç¼“å­˜æº {source} åœ¨è¯·æ±‚çš„æ—¥æœŸèŒƒå›´å†…æ— ä»»ä½•åŒ¹é…æ•°æ®")
            return None

        # 7. å‚ç›´åˆå¹¶æ‰€æœ‰åˆ†ç‰‡
        try:
            full_df = pl.concat(pldfs, how="vertical")

            # 8. æœ€åçš„åˆ—é¡ºåºä¼˜åŒ–
            cols = full_df.columns
            if "DATE" in cols and "ASSET" in cols:
                remaining = [c for c in cols if c not in ["DATE", "ASSET"]]
                full_df = full_df.select(["DATE", "ASSET"] + remaining)

            return full_df

        except Exception as e:
            logger.error(f"âŒ åˆå¹¶æ•°æ®åˆ†ç‰‡å¤±è´¥ ({source}): {e}")
            return None

    def clear_cache(self, source: Optional[str] = None) -> None:
        """æ¸…ç†ç‰©ç†ç¼“å­˜æ–‡ä»¶"""
        self.close_all()
        if source:
            (self.cache_dir / f"{source}.h5").unlink(missing_ok=True)
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†ç¼“å­˜æº: {source}")
        else:
            for f in self.cache_dir.glob("*.h5"):
                f.unlink()
            logger.info("ğŸ—‘ï¸ å·²æ¸…ç†æ‰€æœ‰ HDF5 ç¼“å­˜")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close_all()
