from typing import Union, Literal

import numpy as np
import polars as pl

from alpha_factory.utils.schema import F


def single_calc_quantile_metrics(
    df: Union[pl.DataFrame, pl.LazyFrame],  # ä¿®æ”¹æ”¯æŒ LazyFrame
    factor_col: str,
    ret_col: str,
    date_col: str = F.DATE,
    asset_col: str = F.ASSET,
    pool_mask_col: str = F.POOL_MASK,
    n_bins: int = 10,
    mode: Literal["long_only", "long_short", "active"] = "active",
    period: int = 1,
    cost: float = 0.0025,
    est_turnover: float = 0.2,
    annual_days: int = 251,
    direction: Literal[1, -1] = 1,  # ğŸ†• æ–°å¢æ–¹å‘å‚æ•°
) -> dict:
    """
    è®¡ç®—å•å› å­çš„åˆ†å±‚æ”¶ç›Šè¡¨ç°åŠç»¼åˆè¯„ä»·æŒ‡æ ‡
    1. æ ¹æ®å› å­å€¼å°†è‚¡ç¥¨åˆ†ä¸º n_bins ä¸ªåˆ†å±‚ï¼ˆåˆ†ä½æ•°ï¼‰
    2. æ¨¡æ‹ŸæŒ‰æŒ‡å®šå‘¨æœŸè°ƒä»“ï¼Œè®¡ç®—å„åˆ†å±‚çš„å¹³å‡æ”¶ç›Šç‡
    3. æ ¹æ®è¯„ä¼°æ¨¡å¼è®¡ç®—ç»„åˆæ”¶ç›Šï¼ˆå¤šå¤´ã€å¤šç©ºã€ç›¸å¯¹æ”¶ç›Šï¼‰
    4. æ‰£é™¤äº¤æ˜“æˆæœ¬ï¼Œè®¡ç®—å‡€æ”¶ç›Šæ›²çº¿
    5. è®¡ç®—æ€»æ”¶ç›Šã€å¹´åŒ–æ”¶ç›Šã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ç­‰æŒ‡æ ‡

    Args:
        df: è¾“å…¥æ•°æ®æ¡†ï¼ŒåŒ…å«å› å­åˆ—å’Œæ”¶ç›Šç‡åˆ—
        factor_col: å› å­åˆ—åç§°
        ret_col: æ”¶ç›Šç‡åˆ—åç§°
        date_col: æ—¥æœŸåˆ—åç§°
        asset_col: èµ„äº§åˆ—åç§°
        pool_mask_col: è‚¡ç¥¨æ± æ©ç åˆ—åç§°ï¼ˆTrue = åœ¨æ± å†…ï¼‰
        n_bins: åˆ†å±‚æ•°é‡ï¼ˆåˆ†ä½æ•°ï¼‰
        mode: è¯„ä¼°æ¨¡å¼
            - 'long_only': ä»…å¤šå¤´å¤´å¯¸
            - 'long_short': å¤šç©ºå¤´å¯¸
            - 'active': ç›¸å¯¹äºå¸‚åœºå¹³å‡æ”¶ç›Š
        period: è°ƒä»“å‘¨æœŸï¼ˆå•ä½ï¼šäº¤æ˜“æ—¥ï¼‰
        cost: å•è¾¹äº¤æ˜“è´¹ç”¨ç‡ï¼ˆç”¨äºæ‰£é™¤æˆæœ¬ï¼‰
        est_turnover: ä¼°è®¡çš„æ—¥å‡æ¢æ‰‹ç‡ï¼ˆç”¨äºè®¡ç®—è°ƒä»“æˆæœ¬ï¼‰
        annual_days: å¹´åŒ–äº¤æ˜“æ—¥å¤©æ•°ï¼ˆç”¨äºå¹´åŒ–æ”¶ç›Šè®¡ç®—ï¼‰
        direction: å› å­æ–¹å‘ (1=æ­£å‘, -1=åå‘)ï¼Œå†³å®šå¤šå¤´å’Œç©ºå¤´çš„åˆ†å±‚é€‰æ‹©
    :returns
        dict: åŒ…å«åˆ†å±‚æ”¶ç›Šæ•°æ®å’Œç»¼åˆè¯„ä»·æŒ‡æ ‡çš„å­—å…¸
    ç»“æ„å¦‚ä¸‹ï¼š
        {
            "quantile_daily_ret": pl.DataFrame,  # å„åˆ†å±‚æ¯æ—¥æ”¶ç›Š
            "series": pl.DataFrame,               # å‡€æ”¶ç›Šæ›²çº¿æ•°æ®
            "mode": str,                          # è¯„ä¼°æ¨¡å¼
            "metrics": {                         # ç»¼åˆè¯„ä»·æŒ‡æ ‡
                "total_return": float,
                "annual_return": float,
                "annual_volatility": float,
                "sharpe_ratio": float,
                "max_drawdown": float,
                "win_rate": float,
                "monotonicity": float,
                "smoothness_index": float,
                "avg_count_per_bin": float,
                "total_obs": int,
                "rebalance_period": int,
                "avg_daily_turnover": float
            }
        }
    è¯´æ˜ï¼š
    è¯¥å‡½æ•°å®ç°äº†åŸºäºå› å­åˆ†å±‚çš„æ”¶ç›Šè¯„ä¼°ï¼Œè€ƒè™‘äº†åŠ¨æ€è‚¡ç¥¨æ± å’Œäº¤æ˜“æˆæœ¬ï¼Œèƒ½å¤Ÿå…¨é¢åæ˜ å› å­çš„å®é™…æŠ•èµ„ä»·å€¼ã€‚
    """
    # --- 0. ç»Ÿä¸€è½¬ä¸º LazyFrame ä»¥ä¾¿åˆ©ç”¨ä¸‹å‹ä¼˜åŒ– ---
    lf = df.lazy() if isinstance(df, pl.DataFrame) else df

    # --- 1. æ¨¡æ‹Ÿè°ƒä»“å‘¨æœŸé€»è¾‘ (è¿™é‡Œå¿…é¡» collectï¼Œå› ä¸º Python éœ€è¦æ—¥æœŸåˆ—è¡¨æ¥åšå¾ªç¯) ---
    all_dates = (
        lf.select(date_col)
        .unique()
        .sort(date_col)
        .collect()
        .get_column(date_col)
        .to_list()
    )
    rebalance_dates = [all_dates[i] for i in range(0, len(all_dates), period)]

    # --- 2. åŠ¨æ€è‚¡ç¥¨æ± è¿‡æ»¤ä¸åˆ†å±‚ ---
    working_lf = lf.filter(pl.col(pool_mask_col)) if pool_mask_col else lf

    # åˆ†ç»„åˆ†ä½æ•°è®¡ç®—
    df_with_q = (
        working_lf.with_columns(
            pl.when(pl.col(date_col).is_in(rebalance_dates))
            .then(
                pl.col(factor_col)
                .rank(method="random")
                .over(date_col)
                .qcut(n_bins, labels=[f"Q{i + 1}" for i in range(n_bins)])
            )
            .otherwise(None)
            .alias("quantile")
        )
        .sort([asset_col, date_col])
        .with_columns(pl.col("quantile").forward_fill().over(asset_col))
        .filter(pl.col("quantile").is_not_null())
    )

    # --- 3. èšåˆæ”¶ç›Š ---
    q_rets_lf = df_with_q.group_by([date_col, "quantile"]).agg(
        [
            pl.col(ret_col).mean().alias("ret"),
            pl.len().alias("count"),  # å¢åŠ  count ç”¨äºåç»­ç»Ÿè®¡
        ]
    )

    # Pivot æ“ä½œåœ¨ Polars Lazy ä¸­æ˜¯é˜»å¡çš„ï¼Œä¼šè‡ªåŠ¨è§¦å‘éƒ¨åˆ† collect
    res_series = (
        q_rets_lf.collect()
        .pivot(index=date_col, on="quantile", values="ret")
        .sort(date_col)
    )

    # --- 4. æ‰£é™¤æˆæœ¬ ---
    reb_cost = est_turnover * period * cost
    # --- æ ¹æ®æ–¹å‘ç¡®å®šå¤šå¤´å’Œç©ºå¤´æ¡¶ ---
    if direction == 1:
        long_col = f"Q{n_bins}"  # å› å­å€¼æœ€å¤§ä¸ºå¤šå¤´
        short_col = "Q1"
    else:
        long_col = "Q1"  # å› å­å€¼æœ€å°ä¸ºå¤šå¤´
        short_col = f"Q{n_bins}"
    all_q_cols = [f"Q{i + 1}" for i in range(n_bins)]

    if mode == "long_only":
        res_series = res_series.with_columns(pl.col(long_col).alias("raw_ret"))
    elif mode == "long_short":
        # æ­¤æ—¶å¦‚æœæ˜¯ direction=-1ï¼Œä¼šè‡ªåŠ¨å˜æˆ Q1 - Q10
        res_series = res_series.with_columns(
            (pl.col(long_col) - pl.col(short_col)).alias("raw_ret")
        )
        reb_cost = reb_cost * 2
    elif mode == "active":
        # ä½¿ç”¨ long_col å‡å»æˆªé¢å¹³å‡
        res_series = res_series.with_columns(
            (pl.col(long_col) - pl.mean_horizontal(all_q_cols)).alias("raw_ret")
        )

    res_series = res_series.with_columns(
        pl.when(pl.col(date_col).is_in(rebalance_dates))
        .then(pl.col("raw_ret") - reb_cost)
        .otherwise(pl.col("raw_ret"))
        .alias("target_ret")
    ).with_columns((pl.col("target_ret").fill_null(0) + 1).cum_prod().alias("nav"))

    # --- 5. è®¡ç®—è¯„ä»·æŒ‡æ ‡ ---
    total_days = len(all_dates)
    if total_days <= 1:
        return {"error": "Insufficient data"}

    # ä½¿ç”¨ get_column æ›¿ä»£ [col]
    nav_arr = res_series.get_column("nav").to_numpy()
    target_ret_arr = res_series.get_column("target_ret")

    total_ret = nav_arr[-1] - 1 if len(nav_arr) > 0 else 0.0
    annual_ret = (1 + total_ret) ** (annual_days / total_days) - 1
    annual_vol = target_ret_arr.std() * (annual_days**0.5)
    sharpe_ratio = annual_ret / (annual_vol + 1e-9)

    # æœ€å¤§å›æ’¤
    running_max = np.maximum.accumulate(nav_arr)
    max_drawdown = np.min((nav_arr - running_max) / (running_max + 1e-9))

    # ç¨³å®šæ€§åˆ†æ
    # æ³¨æ„ï¼šq_rets æ­¤æ—¶éœ€è¦ collect
    q_rets_df = q_rets_lf.collect()
    smoothness = _check_factor_smoothness(q_rets_df, n_bins)

    return {
        "quantile_daily_ret": q_rets_df,
        "series": res_series,
        "mode": mode,
        "metrics": {
            "total_return": total_ret,
            "annual_return": annual_ret,
            "annual_volatility": annual_vol,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "win_rate": res_series.filter(pl.col("target_ret") > 0).height / total_days,
            "monotonicity": smoothness["monotonicity_score"],
            "smoothness_index": smoothness["gap_stability"],
            "avg_count_per_bin": q_rets_df.get_column("count").mean(),
            "total_obs": q_rets_df.get_column("count").sum(),
            "rebalance_period": period,
            "avg_daily_turnover": est_turnover,
        },
    }


def _check_factor_smoothness(q_rets: pl.DataFrame, n_bins: int) -> dict:
    """
    åˆ¤æ–­åˆ†å±‚æ”¶ç›Šçš„å¹³æ»‘åº¦
    """
    # 1. è®¡ç®—å„åˆ†å±‚çš„å…¨å‘¨æœŸå¹³å‡æ”¶ç›Š
    mean_rets = q_rets.group_by("quantile").agg(pl.col("ret").mean()).sort("quantile")

    # 2. è®¡ç®—å•è°ƒæ€§å¾—åˆ† (Spearman Rank Correlation)
    # ç†æƒ³å€¼æ˜¯ 1 (ä¸¥æ ¼å•è°ƒé€’å¢) æˆ– -1 (ä¸¥æ ¼å•è°ƒé€’å‡)
    quantile_idx = np.arange(1, n_bins + 1)
    return_values = mean_rets["ret"].to_numpy()

    # ä½¿ç”¨ç®€å•ç›¸å…³ç³»æ•°è¡¡é‡å•è°ƒæ€§
    monotonicity = np.corrcoef(quantile_idx, return_values)[0, 1]

    # 3. è®¡ç®—æ”¶ç›Šé—´è·çš„ç¨³å®šæ€§ (Gap Deviation)
    # å¦‚æœ Q1-Q2, Q2-Q3... çš„é—´è·å‡åŒ€ï¼Œè¯´æ˜å› å­å¯¹å„åˆ†æ®µçš„åŒºåˆ†åº¦éƒ½å¾ˆå¹³æ»‘
    gaps = np.diff(return_values)
    gap_cv = np.std(gaps) / (np.abs(np.mean(gaps)) + 1e-9)  # é—´è·å˜å¼‚ç³»æ•°ï¼Œè¶Šå°è¶Šå¹³æ»‘

    return {
        "monotonicity_score": monotonicity,
        "gap_stability": 1 / (1 + gap_cv),  # å½’ä¸€åŒ–ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¹³æ»‘
    }
