#!/usr/bin/env python3
"""
Alpha-Factory å¤šå¹´ä»½æ•°æ®åŒæ­¥è„šæœ¬ (2019-2024)

ã€åŠŸèƒ½ã€‘
- ä» Tushare è·å– 2019-2024 å¹´å…¨å¸‚åœºè¡Œæƒ…æ•°æ®
- è‡ªåŠ¨å¤„ç†æ•°æ®æ¸…æ´—ã€å¯¹é½ã€å¤æƒè°ƒæ•´
- å¢é‡æ›´æ–°æ”¯æŒï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
- å¤šå¹´ä»½æ•°æ®ç»Ÿä¸€å­˜å‚¨ä¸º Parquet

ã€ä½¿ç”¨ã€‘
python scripts/sync_data_2019_2024.py \\
    --start-year 2019 \\
    --end-year 2024 \\
    --mode full \\
    --resume

ã€è¾“å‡ºç»“æ„ã€‘
data/
â”œâ”€â”€ raw/                          # Tushare åŸå§‹æ•°æ® (HDF5 ç¼“å­˜)
â”‚   â”œâ”€â”€ daily_2019.h5
â”‚   â”œâ”€â”€ daily_2020.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ warehouse/unified_factors/    # æ¸…æ´—åçš„ç»Ÿä¸€å› å­åº“ (Parquet)
    â”œâ”€â”€ 2019.parquet
    â”œâ”€â”€ 2020.parquet
    â””â”€â”€ ...

ã€æ ¸å¿ƒå‚æ•°ã€‘
- start_year, end_year: åŒæ­¥çš„å¹´ä»½èŒƒå›´
- mode: full (å…¨é‡é‡æ–°åŒæ­¥) | incremental (å¢é‡æ›´æ–°)
- resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- overwrite: æ˜¯å¦è¦†ç›–å·²æœ‰æ•°æ®
"""

import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
import json

import polars as pl
from loguru import logger

# é¡¹ç›®è·¯å¾„ä¿®æ­£
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from alpha.data_provider import TushareDataService, DataProvider
from alpha.utils.config import settings
from alpha.utils.logger import setup_logger


class MultiYearDataSyncer:
    """
    å¤šå¹´ä»½æ•°æ®åŒæ­¥åè°ƒå™¨

    èŒè´£ï¼š
    - æŒ‰å¹´ä»½åˆ†æ®µåŒæ­¥æ•°æ®
    - ç®¡ç†ç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ 
    - æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥
    - ç”ŸæˆåŒæ­¥æŠ¥å‘Š
    """

    def __init__(
        self,
        start_year: int,
        end_year: int,
        mode: str = "full",
        resume: bool = True,
        overwrite: bool = False,
        is_vip: bool = True
    ):
        """
        åˆå§‹åŒ–å¤šå¹´ä»½æ•°æ®åŒæ­¥å™¨

        Args:
            start_year: åŒæ­¥èµ·å§‹å¹´ä»½
            end_year: åŒæ­¥ç»“æŸå¹´ä»½
            mode: åŒæ­¥æ¨¡å¼ (full / incremental)
            resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            overwrite: æ˜¯å¦è¦†ç›–å·²æœ‰æ•°æ®
            is_vip: æ˜¯å¦ä½¿ç”¨ Tushare VIP è´¦æˆ· (æ›´é«˜é™æµ)
        """
        self.start_year = start_year
        self.end_year = end_year
        self.mode = mode
        self.resume = resume
        self.overwrite = overwrite

        self.service = TushareDataService(is_vip=is_vip)
        self.data_provider = DataProvider()

        self.sync_stats: Dict[int, Dict[str, Any]] = {}
        self.checkpoint_file = Path(settings.LOG_DIR) / "sync_checkpoint.json"

        logger.info("=" * 70)
        logger.info(f"ğŸš€ å¤šå¹´ä»½æ•°æ®åŒæ­¥é…ç½®")
        logger.info(f"  å¹´ä»½èŒƒå›´: {start_year} - {end_year}")
        logger.info(f"  åŒæ­¥æ¨¡å¼: {mode} | æ–­ç‚¹ç»­ä¼ : {resume}")
        logger.info(f"  è¦†ç›–æ•°æ®: {overwrite} | VIP è´¦æˆ·: {is_vip}")
        logger.info("=" * 70)

    def load_checkpoint(self) -> Dict[str, Any]:
        """
        åŠ è½½æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹

        Returns:
            Dict: æ£€æŸ¥ç‚¹ä¿¡æ¯
        """
        if self.checkpoint_file.exists():
            try:
                with open(self.checkpoint_file, 'r') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"âš ï¸ æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
        return {}

    def save_checkpoint(self, checkpoint: Dict[str, Any]):
        """
        ä¿å­˜æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹

        Args:
            checkpoint: æ£€æŸ¥ç‚¹ä¿¡æ¯
        """
        self.checkpoint_file.parent.mkdir(parents=True, exist_ok=True)
        try:
            with open(self.checkpoint_file, 'w') as f:
                json.dump(checkpoint, f, indent=2)
            logger.debug(f"âœ“ æ£€æŸ¥ç‚¹å·²ä¿å­˜")
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥: {e}")

    def sync_single_year(self, year: int, checkpoint: Dict) -> Dict[str, Any]:
        """
        åŒæ­¥å•ä¸ªå¹´ä»½çš„æ•°æ®

        Args:
            year: ç›®æ ‡å¹´ä»½
            checkpoint: æ–­ç‚¹ä¿¡æ¯

        Returns:
            Dict: åŒæ­¥ç»Ÿè®¡ç»“æœ

        Raises:
            Exception: å¦‚æœåŒæ­¥è¿‡ç¨‹å‡ºç°é”™è¯¯
        """
        logger.info("\n" + "=" * 70)
        logger.info(f"ğŸ“Š åŒæ­¥ {year} å¹´æ•°æ®")
        logger.info("=" * 70)

        start_date = f"{year}0101"
        end_date = f"{year}1231"

        # 1. æ£€æŸ¥æ˜¯å¦å·²åŒæ­¥
        year_checkpoint = checkpoint.get(str(year), {})
        if year_checkpoint.get("status") == "completed" and not self.overwrite:
            logger.info(f"âœ“ {year} å¹´å·²åŒæ­¥ï¼Œè·³è¿‡")
            return {
                "year": year,
                "status": "skipped",
                "reason": "å·²å­˜åœ¨"
            }

        try:
            # 2. åŒæ­¥æ—¥çº¿æ•°æ®
            logger.info(f"ğŸ“¡ ä» Tushare è·å– {start_date} ~ {end_date} æ—¥çº¿æ•°æ®...")
            sync_result = self.service.sync_daily_bars(start_date, end_date)

            # 3. éªŒè¯æ•°æ®
            logger.info("ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
            warehouse_dir = Path(settings.WAREHOUSE_DIR) / "unified_factors"
            parquet_file = warehouse_dir / f"{year}.parquet"

            if parquet_file.exists():
                df = pl.read_parquet(parquet_file)
                row_count = df.height
                col_count = len(df.columns)
                null_ratio = df.null_count().sum() / (row_count * col_count)

                logger.info(f"âœ“ æ•°æ®éªŒè¯é€šè¿‡")
                logger.info(f"  è¡Œæ•°: {row_count:,} | åˆ—æ•°: {col_count}")
                logger.info(f"  ç©ºå€¼ç‡: {null_ratio:.2%}")

                stat = {
                    "year": year,
                    "status": "completed",
                    "rows": row_count,
                    "columns": col_count,
                    "null_ratio": null_ratio,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.warning(f"âš ï¸ {year} å¹´ Parquet æ–‡ä»¶ä¸å­˜åœ¨")
                stat = {
                    "year": year,
                    "status": "warning",
                    "message": "Parquet æ–‡ä»¶ä¸å­˜åœ¨"
                }

            return stat

        except Exception as e:
            logger.error(f"âŒ {year} å¹´åŒæ­¥å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                "year": year,
                "status": "failed",
                "error": str(e)
            }

    def run_all_years(self) -> Dict[int, Dict[str, Any]]:
        """
        æŒ‰å¹´ä»½å¾ªç¯æ‰§è¡Œæ•°æ®åŒæ­¥

        Returns:
            Dict: æ¯ä¸ªå¹´ä»½çš„åŒæ­¥ç»Ÿè®¡ç»“æœ
        """
        logger.info("\nğŸ”„ å¼€å§‹å¤šå¹´ä»½æ•°æ®åŒæ­¥...")

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = self.load_checkpoint() if self.resume else {}

        for year in range(self.start_year, self.end_year + 1):
            result = self.sync_single_year(year, checkpoint)
            self.sync_stats[year] = result

            # æ›´æ–°æ£€æŸ¥ç‚¹
            checkpoint[str(year)] = result
            if self.resume:
                self.save_checkpoint(checkpoint)

        return self.sync_stats

    def generate_summary_report(self) -> str:
        """
        ç”ŸæˆåŒæ­¥æ‘˜è¦æŠ¥å‘Š

        Returns:
            str: æ ¼å¼åŒ–çš„æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = [
            "\n" + "=" * 70,
            "ğŸ“Š Alpha-Factory å¤šå¹´ä»½æ•°æ®åŒæ­¥æŠ¥å‘Š",
            "=" * 70,
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"åŒæ­¥å¹´ä»½: {self.start_year} - {self.end_year}",
            f"åŒæ­¥æ¨¡å¼: {self.mode}",
            "",
            "ã€å¹´ä»½ç»Ÿè®¡ã€‘",
        ]

        total_rows = 0
        success_count = 0

        for year in range(self.start_year, self.end_year + 1):
            if year in self.sync_stats:
                stat = self.sync_stats[year]
                status = stat.get("status", "unknown")

                if status == "completed":
                    rows = stat.get("rows", 0)
                    cols = stat.get("columns", 0)
                    null_ratio = stat.get("null_ratio", 0)
                    total_rows += rows
                    success_count += 1
                    report_lines.append(
                        f"  {year}: âœ… | è¡Œæ•°={rows:7,} | åˆ—æ•°={cols:2d} | ç©ºå€¼={null_ratio:.1%}"
                    )
                elif status == "skipped":
                    report_lines.append(f"  {year}: â­ï¸  | å·²å­˜åœ¨ï¼Œè·³è¿‡")
                else:
                    reason = stat.get("error", stat.get("message", "æœªçŸ¥é”™è¯¯"))
                    report_lines.append(f"  {year}: âŒ | {reason}")
            else:
                report_lines.append(f"  {year}: â“ | æœªåŒæ­¥")

        report_lines.extend([
            "",
            "ã€ç»Ÿè®¡æ±‡æ€»ã€‘",
            f"  æˆåŠŸ: {success_count}/{self.end_year - self.start_year + 1}",
            f"  æ€»æ•°æ®è¡Œæ•°: {total_rows:,}",
            "",
            "ã€è¾“å‡ºä½ç½®ã€‘",
            f"  åŸå§‹æ•°æ®: {Path(settings.RAW_DATA_DIR)}",
            f"  ä»“åº“æ•°æ®: {Path(settings.WAREHOUSE_DIR) / 'unified_factors'}",
            "",
            "ã€åç»­æ­¥éª¤ã€‘",
            "  1. éªŒè¯æ•°æ®å®Œæ•´æ€§",
            "  2. å¯åŠ¨å› å­æŒ–æ˜ (mine_factors_2019_2024.py)",
            "=" * 70,
        ])

        return "\n".join(report_lines)

    def save_summary(self, output_file: Path = None):
        """
        ä¿å­˜åŒæ­¥æ‘˜è¦åˆ°æ–‡ä»¶

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            output_file = Path(settings.REPORT_DIR) / f"sync_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        output_file.parent.mkdir(parents=True, exist_ok=True)

        report = self.generate_summary_report()
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"âœ… æ‘˜è¦å·²ä¿å­˜: {output_file}")


def main():
    """
    CLI ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(
        description="Alpha-Factory å¤šå¹´ä»½æ•°æ®åŒæ­¥è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # å…¨é‡åŒæ­¥ 2019-2024 å¹´
  python sync_data_2019_2024.py --start-year 2019 --end-year 2024 --mode full

  # å¢é‡æ›´æ–°æœ€è¿‘ä¸€å¹´
  python sync_data_2019_2024.py --start-year 2024 --end-year 2024 --mode incremental

  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
  python sync_data_2019_2024.py --start-year 2019 --end-year 2024 --resume

  # è¦†ç›–å·²æœ‰æ•°æ®
  python sync_data_2019_2024.py --start-year 2024 --end-year 2024 --overwrite
        """
    )

    parser.add_argument(
        "--start-year",
        type=int,
        default=2019,
        help="åŒæ­¥èµ·å§‹å¹´ä»½ (é»˜è®¤: 2019)"
    )
    parser.add_argument(
        "--end-year",
        type=int,
        default=2024,
        help="åŒæ­¥ç»“æŸå¹´ä»½ (é»˜è®¤: 2024)"
    )
    parser.add_argument(
        "--mode",
        choices=["full", "incremental"],
        default="full",
        help="åŒæ­¥æ¨¡å¼ï¼šfull (å…¨é‡) æˆ– incremental (å¢é‡ï¼Œé»˜è®¤: full)"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        default=True,
        help="æ”¯æŒæ–­ç‚¹ç»­ä¼  (é»˜è®¤: å¯ç”¨)"
    )
    parser.add_argument(
        "--no-resume",
        dest="resume",
        action="store_false",
        help="ç¦ç”¨æ–­ç‚¹ç»­ä¼ "
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="è¦†ç›–å·²æœ‰æ•°æ®"
    )
    parser.add_argument(
        "--vip",
        action="store_true",
        default=True,
        help="ä½¿ç”¨ Tushare VIP è´¦æˆ· (é»˜è®¤: æ˜¯)"
    )
    parser.add_argument(
        "--no-vip",
        dest="vip",
        action="store_false",
        help="ä¸ä½¿ç”¨ VIP è´¦æˆ·"
    )
    parser.add_argument(
        "--save-summary",
        action="store_true",
        default=True,
        help="ä¿å­˜æ‘˜è¦æŠ¥å‘Š (é»˜è®¤: æ˜¯)"
    )

    args = parser.parse_args()

    # å‚æ•°éªŒè¯
    if args.start_year > args.end_year:
        logger.error("âŒ èµ·å§‹å¹´ä»½ä¸èƒ½æ™šäºç»“æŸå¹´ä»½")
        sys.exit(1)

    if args.start_year < 2015:
        logger.warning("âš ï¸ æ•°æ®ä» 2015 å¹´å¼€å§‹æä¾›")

    # åˆå§‹åŒ–æ—¥å¿—
    setup_logger()

    # åˆ›å»ºåŒæ­¥å™¨
    syncer = MultiYearDataSyncer(
        start_year=args.start_year,
        end_year=args.end_year,
        mode=args.mode,
        resume=args.resume,
        overwrite=args.overwrite,
        is_vip=args.vip
    )

    # æ‰§è¡ŒåŒæ­¥
    try:
        logger.info("ğŸ“¥ å¼€å§‹å¤šå¹´ä»½æ•°æ®åŒæ­¥...")
        results = syncer.run_all_years()

        # ä¿å­˜æ‘˜è¦
        if args.save_summary:
            syncer.save_summary()

        # æ‰“å°æ‘˜è¦
        logger.info(syncer.generate_summary_report())

        logger.info("\nâœ… æ•°æ®åŒæ­¥å…¨æµç¨‹å®Œæˆï¼")
        logger.info("   ä¸‹ä¸€æ­¥ï¼špython scripts/mine_factors_2019_2024.py")
        sys.exit(0)

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ åŒæ­¥è¢«ç”¨æˆ·ä¸­æ–­")
        logger.info("   æ£€æŸ¥ç‚¹å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯é€šè¿‡ --resume æ¢å¤")
        sys.exit(130)

    except Exception as e:
        logger.error(f"\nâŒ åŒæ­¥è¿‡ç¨‹å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()
