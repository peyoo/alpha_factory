#!/usr/bin/env python3
"""
Alpha-Factory å› å­æŒ–æ˜è„šæœ¬ (2019-2024)

ã€åŠŸèƒ½ã€‘
- æ”¯æŒè·¨å¹´ä»½å¤šè½®å› å­æŒ–æ˜
- æ¯ä¸ªå¹´ä»½ç‹¬ç«‹è¿›åŒ–å‘¨æœŸï¼Œé¿å…æ•°æ®æ··æ·†
- è‡ªåŠ¨ç®¡ç†ç¼“å­˜å’Œä¸­é—´ç»“æœ
- æ”¯æŒæ–­ç‚¹æ¢å¤

ã€ä½¿ç”¨ã€‘
python scripts/mine_factors_2019_2024.py \\
    --start-year 2019 \\
    --end-year 2024 \\
    --n-gen 20 \\
    --n-pop 500 \\
    --label RETURN_OO_1 \\
    --overwrite-data

ã€è¾“å‡ºç»“æ„ã€‘
output/gp/
â”œâ”€â”€ 2019_exprs_*.pkl          # æ¯ä»£ç§ç¾¤
â”œâ”€â”€ 2019_best_hof.pkl          # æœ€ä½³å› å­åäººå ‚
â”œâ”€â”€ 2020_exprs_*.pkl
â”œâ”€â”€ ...
â””â”€â”€ 2024_best_hof.pkl

ã€æ ¸å¿ƒå‚æ•°ã€‘
- start_year, end_year: æŒ–æ˜çš„å¹´ä»½èŒƒå›´
- n_gen: æ¯ä¸ªå¹´ä»½çš„è¿›åŒ–ä»£æ•° (æ¨è 15-30)
- n_pop: åˆå§‹ç§ç¾¤å¤§å° (æ¨è 300-500)
- label: ç›®æ ‡æ ‡ç­¾åˆ—å (RETURN_OO_1, target_1d_return ç­‰)
- overwrite_data: æ˜¯å¦è¦†ç›–ç¼“å­˜æ•°æ®
"""

import argparse
import sys
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any
import pickle

import polars as pl
from loguru import logger

# é¡¹ç›®è·¯å¾„ä¿®æ­£
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from alpha.data_provider import DataProvider
from alpha.gp.generator import GPDeapGenerator
from alpha.utils.config import settings
from alpha.utils.logger import setup_logger


class MultiYearMiner:
    """
    å¤šå¹´ä»½å› å­æŒ–æ˜åè°ƒå™¨

    èŒè´£ï¼š
    - æŒ‰å¹´ä»½åˆ†æ®µç»„ç»‡æ•°æ®
    - ä¸ºæ¯ä¸ªå¹´ä»½åˆ›å»ºç‹¬ç«‹çš„ GP ç”Ÿæˆå™¨
    - ç®¡ç†è¿›åŒ–è¿‡ç¨‹å’Œç»“æœæ±‡æ€»
    - ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š
    """

    def __init__(
        self,
        start_year: int,
        end_year: int,
        label_y: str = "RETURN_OO_1",
        n_gen: int = 20,
        n_pop: int = 500,
        batch_size: int = 50,
        overwrite_data: bool = False
    ):
        """
        åˆå§‹åŒ–å¤šå¹´ä»½æŒ–æ˜å™¨

        Args:
            start_year: èµ·å§‹å¹´ä»½ (2019)
            end_year: ç»“æŸå¹´ä»½ (2024)
            label_y: ç›®æ ‡æ ‡ç­¾åˆ—å
            n_gen: æ¯ä¸ªå¹´ä»½çš„è¿›åŒ–ä»£æ•°
            n_pop: åˆå§‹ç§ç¾¤å¤§å°
            batch_size: æ‰¹å¤„ç†å¤§å°
            overwrite_data: æ˜¯å¦è¦†ç›–ç¼“å­˜æ•°æ®
        """
        self.start_year = start_year
        self.end_year = end_year
        self.label_y = label_y
        self.n_gen = n_gen
        self.n_pop = n_pop
        self.batch_size = batch_size
        self.overwrite_data = overwrite_data

        self.data_provider = DataProvider()
        self.results_by_year: Dict[int, Dict[str, Any]] = {}

        logger.info("=" * 70)
        logger.info(f"ğŸš€ å¤šå¹´ä»½å› å­æŒ–æ˜é…ç½®")
        logger.info(f"  å¹´ä»½èŒƒå›´: {start_year} - {end_year}")
        logger.info(f"  ç›®æ ‡æ ‡ç­¾: {label_y}")
        logger.info(f"  è¿›åŒ–ä»£æ•°: {n_gen} | ç§ç¾¤å¤§å°: {n_pop}")
        logger.info(f"  æ‰¹å¤„ç†: {batch_size} | è¦†ç›–æ•°æ®: {overwrite_data}")
        logger.info("=" * 70)

    def _ensure_label_column(self, year: int) -> bool:
        """
        ç¡®ä¿æ•°æ®ä¸­å­˜åœ¨ç›®æ ‡æ ‡ç­¾åˆ—ï¼Œå¦‚ä¸å­˜åœ¨åˆ™è®¡ç®—

        Args:
            year: ç›®æ ‡å¹´ä»½

        Returns:
            bool: æˆåŠŸè¿”å› True

        Raises:
            ValueError: å¦‚æœæ— æ³•è®¡ç®—æ ‡ç­¾åˆ—
        """
        logger.info(f"ğŸ” æ£€æŸ¥æ ‡ç­¾åˆ— '{self.label_y}' æ˜¯å¦å­˜åœ¨...")

        # è¯»å–è¯¥å¹´ä»½æ•°æ®
        warehouse_dir = Path(settings.WAREHOUSE_DIR) / "unified_factors"
        parquet_file = warehouse_dir / f"{year}.parquet"

        if not parquet_file.exists():
            logger.warning(f"âš ï¸ {year} å¹´æ•°æ®ä¸å­˜åœ¨: {parquet_file}")
            return False

        # è¯»å–æ•°æ®
        df = pl.read_parquet(parquet_file)
        available_cols = df.columns

        logger.info(f"âœ“ æ•°æ®åŒ…å« {len(available_cols)} åˆ—")

        # æ£€æŸ¥æ ‡ç­¾åˆ—æ˜¯å¦å­˜åœ¨
        if self.label_y in available_cols:
            logger.info(f"âœ“ æ ‡ç­¾åˆ— '{self.label_y}' å·²å­˜åœ¨")
            return True

        # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•è®¡ç®—
        logger.info(f"âš ï¸ æ ‡ç­¾åˆ— '{self.label_y}' ä¸å­˜åœ¨ï¼Œå°è¯•è®¡ç®—...")

        # RETURN_OO_1 = å¼€ç›˜åˆ°å¼€ç›˜ 1 å¤©æ”¶ç›Šç‡
        if self.label_y == "RETURN_OO_1":
            if "OPEN" not in available_cols:
                raise ValueError(f"æ— æ³•è®¡ç®— {self.label_y}ï¼šç¼ºå°‘ OPEN åˆ—")

            logger.info(f"ğŸ“Š è®¡ç®— {self.label_y} = (next_OPEN - OPEN) / OPEN")

            df_with_label = df.with_columns([
                (
                    (pl.col("OPEN").shift(-1).over("ASSET") - pl.col("OPEN"))
                    / pl.col("OPEN")
                ).alias(self.label_y)
            ])

            df_with_label.write_parquet(parquet_file, compression="snappy")
            logger.info(f"âœ… æ ‡ç­¾åˆ—å·²è®¡ç®—å¹¶ä¿å­˜")
            return True

        elif self.label_y == "target_1d_return":
            if "CLOSE" not in available_cols:
                raise ValueError(f"æ— æ³•è®¡ç®— {self.label_y}ï¼šç¼ºå°‘ CLOSE åˆ—")

            logger.info(f"ğŸ“Š è®¡ç®— {self.label_y} = (next_CLOSE - CLOSE) / CLOSE")

            df_with_label = df.with_columns([
                (
                    (pl.col("CLOSE").shift(-1).over("ASSET") - pl.col("CLOSE"))
                    / pl.col("CLOSE")
                ).alias(self.label_y)
            ])

            df_with_label.write_parquet(parquet_file, compression="snappy")
            logger.info(f"âœ… æ ‡ç­¾åˆ—å·²è®¡ç®—å¹¶ä¿å­˜")
            return True

        elif self.label_y == "target_5d_return":
            if "CLOSE" not in available_cols:
                raise ValueError(f"æ— æ³•è®¡ç®— {self.label_y}ï¼šç¼ºå°‘ CLOSE åˆ—")

            logger.info(f"ğŸ“Š è®¡ç®— {self.label_y} = 5 å¤©åæ”¶ç›Šç‡")

            df_with_label = df.with_columns([
                (
                    (pl.col("CLOSE").shift(-5).over("ASSET") - pl.col("CLOSE"))
                    / pl.col("CLOSE")
                ).alias(self.label_y)
            ])

            df_with_label.write_parquet(parquet_file, compression="snappy")
            logger.info(f"âœ… æ ‡ç­¾åˆ—å·²è®¡ç®—å¹¶ä¿å­˜")
            return True

        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æ ‡ç­¾åˆ—: {self.label_y}\n"
                f"æ”¯æŒçš„é€‰é¡¹: RETURN_OO_1, target_1d_return, target_5d_return"
            )

    def mine_single_year(self, year: int) -> Dict[str, Any]:
        """
        ä¸ºå•ä¸ªå¹´ä»½æ‰§è¡Œå› å­æŒ–æ˜

        Args:
            year: ç›®æ ‡å¹´ä»½

        Returns:
            Dict: æŒ–æ˜ç»“æœ (ç§ç¾¤ã€è¿›åŒ–æ—¥å¿—ã€åäººå ‚)

        Raises:
            ValueError: å¦‚æœæ•°æ®æ— æ³•åŠ è½½æˆ–é…ç½®é”™è¯¯
        """
        logger.info("\n" + "=" * 70)
        logger.info(f"ğŸ“Š å¼€å§‹æŒ–æ˜ {year} å¹´æ•°æ®")
        logger.info("=" * 70)

        # 1. é…ç½®å‚æ•°
        config = {
            "label_y": self.label_y,
            "split_date": datetime(year - 1, 12, 31),  # å‰ä¸€å¹´æœ€åä¸€å¤©ä½œä¸ºåˆ†å‰²ç‚¹
            "batch_size": self.batch_size,
            "mu": self.n_pop // 2,
            "lambda": self.n_pop // 2,
            "hof_size": max(100, self.n_pop // 5)
        }

        # 2. åˆ›å»º GP ç”Ÿæˆå™¨
        try:
            generator = GPDeapGenerator(config)
        except Exception as e:
            logger.error(f"âŒ åˆ›å»º GP ç”Ÿæˆå™¨å¤±è´¥: {e}")
            raise

        # 3. æ„å»ºå¹´ä»½ç‰¹å®šçš„è¾“å‡ºç›®å½•
        year_output_dir = Path(settings.GP_DEAP_DIR) / str(year)
        year_output_dir.mkdir(parents=True, exist_ok=True)

        # ä¸´æ—¶ä¿®æ”¹ generator çš„è¾“å‡ºç›®å½•
        generator.save_dir = year_output_dir
        generator.data_cache_dir = year_output_dir / "data_cache"
        generator.data_cache_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"âœ“ è¾“å‡ºç›®å½•: {year_output_dir}")

        # 4. ç¡®ä¿æ ‡ç­¾åˆ—å­˜åœ¨
        try:
            self._ensure_label_column(year)
        except Exception as e:
            logger.error(f"âŒ {year} å¹´æ ‡ç­¾åˆ—æ£€æŸ¥/è®¡ç®—å¤±è´¥: {e}")
            raise

        # 5. æ‰§è¡Œå…¨æµç¨‹æŒ–æ˜
        try:
            result = generator.run_workflow(
                data_provider=self.data_provider,
                n_gen=self.n_gen,
                overwrite_data=self.overwrite_data
            )
            pop, logbook, hof = result

            # 6. ä¿å­˜ç»“æœ
            result_dict = {
                "year": year,
                "population": pop,
                "logbook": logbook,
                "halloffame": hof,
                "config": config,
                "timestamp": datetime.now().isoformat()
            }

            # ä¿å­˜åˆ° pickle
            result_path = year_output_dir / f"{year}_result.pkl"
            try:
                with open(result_path, 'wb') as f:
                    pickle.dump(result_dict, f)
                logger.info(f"ğŸ’¾ æŒ–æ˜ç»“æœå·²ä¿å­˜: {result_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ç»“æœä¿å­˜å¤±è´¥: {e}")

            logger.info(f"âœ… {year} å¹´æŒ–æ˜å®Œæˆ")
            logger.info(f"   æœ€ç»ˆç§ç¾¤: {len(pop)} | åäººå ‚: {len(hof)}")

            return result_dict

        except Exception as e:
            logger.error(f"âŒ {year} å¹´æŒ–æ˜å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def run_all_years(self) -> Dict[int, Dict[str, Any]]:
        """
        æŒ‰å¹´ä»½å¾ªç¯æ‰§è¡Œå› å­æŒ–æ˜

        Returns:
            Dict: æ¯ä¸ªå¹´ä»½çš„æŒ–æ˜ç»“æœæ±‡æ€»

        Raises:
            RuntimeError: å¦‚æœä»»ä½•å¹´ä»½æŒ–æ˜å¤±è´¥
        """
        logger.info("\nğŸ”„ å¼€å§‹å¤šå¹´ä»½å› å­æŒ–æ˜å¾ªç¯...")

        failed_years = []
        for year in range(self.start_year, self.end_year + 1):
            try:
                result = self.mine_single_year(year)
                self.results_by_year[year] = result
            except Exception as e:
                logger.error(f"âŒ {year} å¹´æŒ–æ˜å¤±è´¥ï¼Œè·³è¿‡")
                failed_years.append(year)
                continue

        # 7. æ€»ç»“æŠ¥å‘Š
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“ˆ å¤šå¹´ä»½æŒ–æ˜å®Œæˆæ€»ç»“")
        logger.info("=" * 70)

        success_years = [y for y in range(self.start_year, self.end_year + 1) if y not in failed_years]
        logger.info(f"âœ… æˆåŠŸå¹´ä»½: {success_years}")
        if failed_years:
            logger.warning(f"âš ï¸ å¤±è´¥å¹´ä»½: {failed_years}")

        for year in success_years:
            result = self.results_by_year[year]
            logger.info(f"  {year}: ç§ç¾¤={len(result['population'])} | åäººå ‚={len(result['halloffame'])}")

        return self.results_by_year

    def generate_summary_report(self) -> str:
        """
        ç”Ÿæˆè¿›åŒ–æ‘˜è¦æŠ¥å‘Š

        Returns:
            str: æ ¼å¼åŒ–çš„æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = [
            "\n" + "=" * 70,
            "ğŸ“Š Alpha-Factory å¤šå¹´ä»½å› å­æŒ–æ˜æŠ¥å‘Š",
            "=" * 70,
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"æŒ–æ˜å¹´ä»½: {self.start_year} - {self.end_year}",
            f"ç›®æ ‡æ ‡ç­¾: {self.label_y}",
            f"è¿›åŒ–ä»£æ•°: {self.n_gen}",
            f"ç§ç¾¤å¤§å°: {self.n_pop}",
            "",
            "ã€å¹´ä»½ç»Ÿè®¡ã€‘",
        ]

        for year in range(self.start_year, self.end_year + 1):
            if year in self.results_by_year:
                result = self.results_by_year[year]
                pop_size = len(result['population'])
                hof_size = len(result['halloffame'])
                report_lines.append(
                    f"  {year}: âœ… å®Œæˆ | ç§ç¾¤={pop_size:3d} | åäººå ‚={hof_size:3d}"
                )
            else:
                report_lines.append(f"  {year}: âŒ æœªå®Œæˆ")

        report_lines.extend([
            "",
            "ã€è¾“å‡ºç›®å½•ã€‘",
            f"  {Path(settings.GP_DEAP_DIR)}",
            "",
            "ã€åç»­æ­¥éª¤ã€‘",
            "  1. æ£€æŸ¥å„å¹´ä»½çš„åäººå ‚å› å­",
            "  2. å¯¹æœ€ä¼˜å› å­è¿›è¡Œæ•ˆæœè¯„ä¼°",
            "  3. è¿›è¡Œå¤šå› å­åˆæˆä¸å›æµ‹",
            "=" * 70,
        ])

        return "\n".join(report_lines)

    def save_summary(self, output_file: Path = None):
        """
        ä¿å­˜æŒ–æ˜æ‘˜è¦åˆ°æ–‡ä»¶

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º reports/mining_summary.txt
        """
        if output_file is None:
            output_file = Path(settings.REPORT_DIR) / f"mining_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        output_file.parent.mkdir(parents=True, exist_ok=True)

        report = self.generate_summary_report()
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"âœ… æ‘˜è¦å·²ä¿å­˜: {output_file}")


def main():
    """
    CLI ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(
        description="Alpha-Factory å¤šå¹´ä»½å› å­æŒ–æ˜è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # æŒ–æ˜ 2019-2024 å¹´ï¼Œ20 ä»£ï¼Œ500 ç§ç¾¤
  python mine_factors_2019_2024.py --start-year 2019 --end-year 2024 --n-gen 20 --n-pop 500

  # å¿«é€Ÿæµ‹è¯• (2023 å¹´ï¼Œ5 ä»£ï¼Œ100 ç§ç¾¤)
  python mine_factors_2019_2024.py --start-year 2023 --end-year 2023 --n-gen 5 --n-pop 100

  # è¦†ç›–ç¼“å­˜é‡æ–°æŒ–æ˜
  python mine_factors_2019_2024.py --start-year 2024 --end-year 2024 --n-gen 15 --overwrite-data
        """
    )

    parser.add_argument(
        "--start-year",
        type=int,
        default=2019,
        help="æŒ–æ˜èµ·å§‹å¹´ä»½ (é»˜è®¤: 2019)"
    )
    parser.add_argument(
        "--end-year",
        type=int,
        default=2024,
        help="æŒ–æ˜ç»“æŸå¹´ä»½ (é»˜è®¤: 2024)"
    )
    parser.add_argument(
        "--n-gen",
        type=int,
        default=20,
        help="æ¯ä¸ªå¹´ä»½çš„è¿›åŒ–ä»£æ•° (é»˜è®¤: 20)"
    )
    parser.add_argument(
        "--n-pop",
        type=int,
        default=500,
        help="åˆå§‹ç§ç¾¤å¤§å° (é»˜è®¤: 500)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=50,
        help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 50)"
    )
    parser.add_argument(
        "--label",
        type=str,
        default="RETURN_OO_1",
        help="ç›®æ ‡æ ‡ç­¾åˆ—å (é»˜è®¤: RETURN_OO_1)"
    )
    parser.add_argument(
        "--overwrite-data",
        action="store_true",
        help="æ˜¯å¦è¦†ç›–å·²æœ‰ç¼“å­˜æ•°æ®"
    )
    parser.add_argument(
        "--save-summary",
        action="store_true",
        default=True,
        help="æ˜¯å¦ä¿å­˜æ‘˜è¦æŠ¥å‘Š (é»˜è®¤: True)"
    )

    args = parser.parse_args()

    # å‚æ•°éªŒè¯
    if args.start_year > args.end_year:
        logger.error("âŒ èµ·å§‹å¹´ä»½ä¸èƒ½æ™šäºç»“æŸå¹´ä»½")
        sys.exit(1)

    if args.start_year < 2015 or args.end_year > 2025:
        logger.warning(f"âš ï¸ å»ºè®®å¹´ä»½èŒƒå›´åœ¨ 2015-2025 ä¹‹é—´")

    if args.n_gen < 5:
        logger.warning("âš ï¸ è¿›åŒ–ä»£æ•°è¿‡å°‘ï¼Œå¯èƒ½éš¾ä»¥æ”¶æ•›")

    if args.n_pop < 100:
        logger.warning("âš ï¸ ç§ç¾¤è¿‡å°ï¼Œå¯èƒ½éš¾ä»¥æ¢ç´¢")

    # åˆå§‹åŒ–æ—¥å¿—
    setup_logger()

    # åˆ›å»ºæŒ–æ˜å™¨
    miner = MultiYearMiner(
        start_year=args.start_year,
        end_year=args.end_year,
        label_y=args.label,
        n_gen=args.n_gen,
        n_pop=args.n_pop,
        batch_size=args.batch_size,
        overwrite_data=args.overwrite_data
    )

    # æ‰§è¡ŒæŒ–æ˜
    try:
        results = miner.run_all_years()

        # ä¿å­˜æ‘˜è¦
        if args.save_summary:
            miner.save_summary()

        # æ‰“å°æ‘˜è¦
        logger.info(miner.generate_summary_report())

        logger.info("\nâœ… å› å­æŒ–æ˜å…¨æµç¨‹å®Œæˆï¼")
        sys.exit(0)

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ æŒ–æ˜è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)

    except Exception as e:
        logger.error(f"\nâŒ æŒ–æ˜è¿‡ç¨‹å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()
