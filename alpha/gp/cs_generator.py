import random
import time
from datetime import datetime
from typing import Sequence

import expr_codegen.polars.code
import numpy as np
import polars as pl
from expr_codegen.expr import TS, CS, GP
from expr_codegen.tool import ExprTool
from loguru import logger
from polars import selectors as cs
from deap import gp
from alpha.gp.base import Expr, dummy
from alpha.gp.base import get_fitness

from alpha.gp.generator import GPDeapGenerator

def get_groupby_from_tuple(tup, func_name, drop_cols):
    """ä»ä¼ å…¥çš„å…ƒç»„ä¸­ç”Ÿæˆåˆ†ç»„è¿è¡Œä»£ç """
    prefix2, *_ = tup

    if len(drop_cols)>0:
        drop_str = f'.drop(*{drop_cols})'
    else:
        drop_str = ""

    if prefix2 == TS:
        # ç»„å†…éœ€è¦æŒ‰æ—¶é—´è¿›è¡Œæ’åºï¼Œéœ€è¦ç»´æŒé¡ºåº
        prefix2, asset = tup
        return f'df = {func_name}(df){drop_str}'
    if prefix2 == CS:
        prefix2, date = tup
        return f'df = {func_name}(df){drop_str}'
    if prefix2 == GP:
        prefix2, date, group = tup
        return f'df = {func_name}(df){drop_str}'

    return f'df = {func_name}(df){drop_str}'

# æ‰“ä¸ªè¡¥ä¸ï¼Œå–æ¶ˆæ’åº
expr_codegen.polars.code.get_groupby_from_tuple = get_groupby_from_tuple

# 1. æ·»åŠ æ—¶åºçª—å£å¸¸é‡
def _random_window_int() -> int:
    """
    ç”Ÿæˆéšæœºçª—å£å¤§å°å¸¸é‡
    è¿™äº›çª—å£å¤§å°è¦†ç›–äº†å¸¸è§çš„çŸ­ä¸­é•¿æœŸè¶‹åŠ¿åˆ†æéœ€æ±‚ã€‚
    å…¨å‘¨æœŸçª—å£é‡‡æ ·ï¼š
    - æçŸ­çº¿ (3, 5): 25% æ¦‚ç‡
    - çŸ­ä¸­çº¿ (10, 20, 40): 50% æ¦‚ç‡ (æ ¸å¿ƒäº¤æ˜“é¢‘ç‡)
    - é•¿çº¿ (60, 120, 250): 25% æ¦‚ç‡ (å­£/åŠå¹´/å¹´çº¿)
    """
    p = random.random()
    if p < 0.25:
        return random.choice([3, 5])
    elif p < 0.75:
        return random.choice([10, 20, 40])  # å¯¹åº” 2å‘¨, 1æœˆ, 2æœˆ
    else:
        return random.choice([60, 120, 250])  # å¯¹åº” 1å­£, åŠå¹´, 1å¹´


class CSGPGenerator(GPDeapGenerator):
    """åŸºäºæˆªé¢å› å­æŒ–æ˜çš„GPå› å­ç”Ÿæˆå™¨"""

    def _build_pset(self) -> gp.PrimitiveSetTyped:
        """
        ç²¾ç®€ç‰ˆç®—å­é›†ï¼šä¸“ä¸º LightGBM/ElasticNet ç‰¹å¾å·¥ç¨‹è®¾è®¡
        æ‰€æœ‰ç®—å­å‡è¿”å›æ•°å€¼ç±»å‹ï¼Œç§»é™¤äº†å¯¼è‡´ SchemaError çš„é€»è¾‘ç®—å­
        """
        # ç›´æ¥ä½¿ç”¨ Expr ä½œä¸ºæ ‡è¯†ï¼Œé»˜è®¤å³ä¸ºæµ®ç‚¹æ•°åºåˆ—
        pset = gp.PrimitiveSetTyped("MAIN", [], Expr)

        # 1. ç»ˆç«¯ (Terminals)
        # AMOUNTæœ‰æå¼ºçš„å¸‚å€¼æ•ˆåº”ï¼Œä¸é€‚åˆæˆªé¢å› å­æŒ–æ˜
        for factor in ['OPEN', 'HIGH', 'LOW', 'CLOSE','TURNOVER_RATE']:
            pset.addTerminal(1, Expr, name=factor)

        # 2. çª—å£å‚æ•° (Constants)
        pset.addEphemeralConstant("rand_int", _random_window_int, int)

        # 3. åŸºç¡€ç®—æœ¯ç®—å­ (çº¿æ€§æ¨¡å‹ ElasticNet æ— æ³•è‡ªå­¦é™¤æ³•å’Œä¹˜æ³•äº¤äº’)
        for name in ['add', 'sub', 'mul', 'div', 'max', 'min']:
            pset.addPrimitive(dummy, [Expr, Expr], Expr, name=f'oo_{name}')

        # 4. æ—¶åºç»Ÿè®¡ç®—å­ (LightGBM çš„ç›²åŒºï¼šæ— æ³•è·¨è¡Œæ„ŸçŸ¥å†å²)
        # ts_mean:æœ€åŸºç¡€çš„è¶‹åŠ¿ä¸­æ¢ï¼ˆå‡çº¿ï¼‰ã€‚å®ƒæä¾›äº†ä»·æ ¼çš„â€œé”šç‚¹â€ã€‚
        # ts_std_dev:æ³¢åŠ¨ç‡æ˜¯é‡‘èå¸‚åœºä¸­ä¿¡æ¯å«é‡æœ€é«˜çš„ç‰¹å¾ä¹‹ä¸€ã€‚æ ‘æ¨¡å‹å¯¹åŸå§‹æ”¶ç›Šç‡æ•æ„Ÿï¼Œä½†æ— æ³•ç›´æ¥æ¨ç®—å½“å‰æ˜¯å¦å¤„äºâ€œé«˜æ³¢åŠ¨ç¯å¢ƒâ€ã€‚
        # ts_max / ts_min:æå€¼ç‚¹å¾€å¾€å¯¹åº”æ”¯æ’‘é˜»åŠ›ä½ï¼Œå¸®åŠ©æ¨¡å‹æ•æ‰åè½¬ä¿¡å·ã€‚
        # ts_delta:è¡¡é‡å½“å‰ä»·æ ¼ä¸è¿‡å»ä»·æ ¼çš„å·®å¼‚ï¼Œæ•æ‰åŠ¨é‡æ•ˆåº”ã€‚
        # ts_returns:ç›´æ¥æä¾›æ”¶ç›Šç‡ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£ä»·æ ¼å˜åŠ¨ã€‚
        # ts_rank:æä¾›å½“å‰ä»·æ ¼åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å†…çš„ç›¸å¯¹ä½ç½®ï¼Œè¾…åŠ©æ¨¡å‹è¯†åˆ«è¶…ä¹°è¶…å–çŠ¶æ€ã€‚æ ¸å¿ƒç‰¹å¾ã€‚å®ƒå°†ä»·æ ¼è½¬åŒ–æˆ 0-1 çš„æ¯”ä¾‹
        # ts_skewness:è¡¡é‡æ”¶ç›Šç‡åˆ†å¸ƒçš„åæ€ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£æç«¯äº‹ä»¶çš„é£é™©ã€‚
        # å¯é€‰ï¼šts_sum, ts_kurtosis,ts_delay,ts_arg_max,ts_arg_min
        ts_ops = [
            'ts_mean', 'ts_std_dev', 'ts_max', 'ts_min','ts_delta', 'ts_returns', 'ts_rank', 'ts_skewness'
        ]
        for op in ts_ops:
            pset.addPrimitive(dummy, [Expr, int], Expr, name=op)
        # æ—¶åºç›¸å…³æ€§ä¸åæ–¹å·® (å¢å¼ºæ¨¡å‹å¯¹å¤šå› å­è”åŠ¨çš„æ„ŸçŸ¥),æå…¶å¼ºå¤§ã€‚
        # ä¾‹å¦‚æˆäº¤é‡å’Œä»·æ ¼çš„ç›¸å…³æ€§ï¼ˆä»·å‡é‡å¢ vs ä»·å‡é‡å‡ï¼‰ã€‚è¿™æ˜¯ ML æ¨¡å‹ç»å¯¹æ— æ³•é€šè¿‡åŸå§‹ç‰¹å¾è‡ªå·±ç®—å‡ºæ¥çš„äº¤äº’ä¿¡æ¯ã€‚
        pset.addPrimitive(dummy, [Expr, Expr, int], Expr, name='ts_corr')
        # é‡åŒ–ä¸¤ä¸ªåºåˆ—çš„åŒæ­¥è¿åŠ¨ç¨‹åº¦ï¼Œæ˜¯ ts_corr çš„æœªå½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œèƒ½ä¿ç•™æ•°å€¼è§„æ¨¡ä¿¡æ¯ã€‚
        # pset.addPrimitive(dummy, [Expr, Expr, int], Expr, name='ts_covariance')

        # 5. æˆªé¢å½’ä¸€åŒ–ç®—å­ (æœºå™¨å­¦ä¹ æ¨¡å‹çš„å…³é”®ï¼šæä¾›æ ·æœ¬é—´çš„ç›¸å¯¹åæ ‡)
        # ç²¾ç»†åŒ–å»ºè®®ï¼š'cs_demean','cs_qcut'
        cs_ops = ['cs_rank', 'cs_zscore']
        for op in cs_ops:
            pset.addPrimitive(dummy, [Expr], Expr, name=op)

        # 6. æ•°å€¼å˜æ¢ (æ”¹å–„çº¿æ€§æ¨¡å‹çš„ç‰¹å¾åˆ†å¸ƒ)
        # å¯é€‰:sigmoid / tanh (è½¯æˆªæ–­)
        for op in ['abs_', 'log', 'sqrt', 'sign']:
            pset.addPrimitive(dummy, [Expr], Expr, name=op)

        return pset


    def fitness_population(self,df: pl.DataFrame, columns: Sequence[str], label: str, split_date: datetime):
        """ç§ç¾¤fitnesså‡½æ•°"""
        if df is None:
            return {}, {}, {}, {}

        # å°†æ‰€æœ‰æ•°å€¼åˆ—è½¬æ¢ä¸º Float64ï¼Œé¿å…ç±»å‹ä¸åŒ¹é…
        df = df.with_columns(cs.numeric().cast(pl.Float64))

        df = df.group_by('DATE').agg(
            [self.fitness_individual(X, label) for X in columns]
        ).sort(by=['DATE']).fill_nan(None)
        # å°†ICåˆ’åˆ†æˆè®­ç»ƒé›†ä¸æµ‹è¯•é›†
        df_train = df.filter(pl.col('DATE') < split_date)
        df_valid = df.filter(pl.col('DATE') >= split_date)

        # TODO æœ‰æ•ˆæ•°ä¸è¶³ï¼Œç”Ÿæˆçš„æ„ä¹‰ä¸å¤§ï¼Œè¿”å›null, è€Œé€‚åº”åº¦ç¬¬0ä½æ˜¯nanæ—¶ä¸åŠ å…¥åäººå ‚
        # cs.numeric().count() / cs.numeric().len() >= 0.5
        # cs.numeric().count() >= 30
        ic_train = df_train.select(
            pl.when(cs.numeric().is_not_null().mean() >= 0.5).then(cs.numeric().mean()).otherwise(None))
        ic_valid = df_valid.select(cs.numeric().mean())
        ir_train = df_train.select(cs.numeric().mean() / cs.numeric().std(ddof=0))
        ir_valid = df_valid.select(cs.numeric().mean() / cs.numeric().std(ddof=0))

        ic_train = ic_train.to_dicts()[0]
        ic_valid = ic_valid.to_dicts()[0]
        ir_train = ir_train.to_dicts()[0]
        ir_valid = ir_valid.to_dicts()[0]

        return ic_train, ic_valid, ir_train, ir_valid

    def batched_exprs(self,batch_id, exprs_list, gen, label, split_date, df_input):
        """æ¯ä»£ç§ç¾¤åˆ†æ‰¹è®¡ç®—

        ç”±äºç§ç¾¤æ•°å¤§ï¼Œä¸€æ¬¡æ€§è®¡ç®—å¯èƒ½å†…å­˜ä¸è¶³ï¼Œæ‰€ä»¥æä¾›åˆ†æ‰¹è®¡ç®—åŠŸèƒ½ï¼ŒåŒæ—¶ä¹Ÿä¸ºåˆ†å¸ƒå¼è®¡ç®—åšå‡†å¤‡
        """
        if len(exprs_list) == 0:
            return {}

        tool = ExprTool()
        # è¡¨è¾¾å¼è½¬è„šæœ¬
        codes, G = tool.all(exprs_list, style='polars', template_file='template.py.j2',
                            replace=False, regroup=True, format=True,
                            date='DATE', asset='ASSET', over_null=None,
                            skip_simplify=True)


        cnt = len(exprs_list)
        logger.info("{}ä»£{}æ‰¹ ä»£ç  å¼€å§‹æ‰§è¡Œã€‚å…± {} æ¡ è¡¨è¾¾å¼", gen, batch_id, cnt)
        tic = time.perf_counter()

        globals_ = {}
        exec(codes, globals_)
        df_output = globals_['main'](df_input.lazy(), ge_date_idx=0).collect()

        elapsed_time = time.perf_counter() - tic
        logger.info("{}ä»£{}æ‰¹ å› å­ è®¡ç®—å®Œæˆã€‚å…±ç”¨æ—¶ {:.3f} ç§’ï¼Œå¹³å‡ {:.3f} ç§’/æ¡ï¼Œæˆ– {:.3f} æ¡/ç§’", gen, batch_id,
                    elapsed_time, elapsed_time / cnt, cnt / elapsed_time)

        # è®¡ç®—ç§ç¾¤é€‚åº”åº¦
        ic_train, ic_valid, ir_train, ir_valid = self.fitness_population(df_output, [k for k, v, c in exprs_list],
                                                                    label=label, split_date=split_date)
        logger.info("{}ä»£{}æ‰¹ é€‚åº”åº¦ è®¡ç®—å®Œæˆ", gen, batch_id)

        # æ ·æœ¬å†…å¤–é€‚åº”åº¦æå–
        new_results = {}
        for k, v, c in exprs_list:
            v = str(v)
            new_results[v] = {'ic_train': get_fitness(k, ic_train),
                              'ic_valid': get_fitness(k, ic_valid),
                              'ir_train': get_fitness(k, ir_train),
                              'ir_valid': get_fitness(k, ir_valid),
                              }
        return new_results

    def fill_fitness(self,exprs_old, fitness_results):
        """å¡«å……fitness"""
        results = []
        for k, v, c in exprs_old:
            v = str(v)
            d = fitness_results.get(v, None)
            if d is None:
                logger.debug('{} ä¸åˆæ³•/æ— æ„ä¹‰/é‡å¤ ç­‰åŸå› ï¼Œåœ¨è®¡ç®—å‰å°±è¢«å‰”é™¤äº†', v)
            else:
                s0, s1, s2, s3 = d['ic_train'], d['ic_valid'], d['ir_train'], d['ir_valid']
                # icè¦çœ‹ç»å¯¹å€¼
                s0, s1, s2, s3 = abs(s0), abs(s1), s2, s3
                # TODO è¿™åœ°æ–¹è¦æŒ‰è‡ªå·±éœ€æ±‚å®šåˆ¶ï¼Œè¿‡æ»¤å¤ªå¤šå¯èƒ½æ— æ³•è¾“å‡ºæœ‰æ•ˆè¡¨è¾¾å¼
                if s0 == s0:  # éç©º
                    if s0 > 0.001:  # æ ·æœ¬å†…æ‰“åˆ†è¦å¤§
                        if s0 * 0.6 < s1:  # æ ·æœ¬å¤–æ‰“åˆ†å¤§äºæ ·æœ¬å†…æ‰“åˆ†çš„60%
                            # å¯ä»¥å‘fitnessæ·»åŠ å¤šä¸ªå€¼ï¼Œä½†é•¿åº¦è¦ä¸weightå®Œå…¨ä¸€æ ·
                            results.append((s0, s1))
                            continue
            # å¯ä»¥å‘fitnessæ·»åŠ å¤šä¸ªå€¼ï¼Œä½†é•¿åº¦è¦ä¸weightå®Œå…¨ä¸€æ ·
            results.append((np.nan, np.nan))

        return results

    def export_hof_to_csv(self, hof, globals_, filename="cs_best_factors.csv"):
        """
        å¯¼å‡ºæˆªé¢æŒ–æ˜çš„åäººå ‚å› å­ï¼ŒåŒ…å« IC å’Œ IR æŒ‡æ ‡
        """
        import pandas as pd
        from alpha.gp.base import population_to_exprs

        # 1. è§£æè¡¨è¾¾å¼
        exprs_list = population_to_exprs(hof, globals_)

        # 2. ä»ç¼“å­˜ä¸­è·å–è¯¦ç»†çš„æŒ‡æ ‡
        # æ³¨æ„ï¼šbatched_exprs è®¡ç®—æ—¶ä¼šå°†ç»“æœå­˜å…¥ fitness_cache.pkl
        # è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä»ä¸ªä½“å¯¹è±¡çš„ fitness å±æ€§å’Œè®¡ç®—é€»è¾‘ä¸­è¿˜åŸ
        data = []
        for (k, v, c), ind in zip(exprs_list, hof):
            # è·å– DEAP å­˜å‚¨çš„ç»å¯¹å€¼ IC (å› ä¸º fill_fitness åšäº† abs())
            ic_train_abs, ic_valid_abs = ind.fitness.values

            data.append({
                "factor_name": k,
                "abs_ic_train": round(ic_train_abs, 5),
                "abs_ic_valid": round(ic_valid_abs, 5),
                "complexity": c,
                "expression": v,
                "raw_tree": str(ind),
                "export_time": datetime.now().strftime("%Y-%m-%d %H:%M")
            })

        df = pd.DataFrame(data)
        # æŒ‰ç…§æ ·æœ¬å†… IC æ’åº
        df = df.sort_values("abs_ic_train", ascending=False)

        output_path = self.save_dir / filename
        df.to_csv(output_path, index=False, encoding='utf-8-sig')

        logger.info(f"ğŸ“Š æˆªé¢å› å­æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return df
