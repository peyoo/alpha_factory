"""
GP å› å­ç”Ÿæˆå™¨ä¸»ç±»

ä½¿ç”¨ DEAP åº“è¿›è¡Œé—ä¼ ç¼–ç¨‹ï¼Œè‡ªåŠ¨åŒ–å› å­æŒ–æ˜ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åŸºäºé—ä¼ ç¼–ç¨‹è‡ªåŠ¨ç”Ÿæˆå› å­è¡¨è¾¾å¼
2. æ‰¹é‡è®¡ç®—å’Œè¯„ä¼°å› å­é€‚åº”åº¦
3. æ”¯æŒè¿›åŒ–è¿‡ç¨‹çš„æ–­ç‚¹æ¢å¤
4. è‡ªåŠ¨ç¼“å­˜ä¸­é—´ç»“æœ

å…¸å‹ç”¨æ³•ï¼š
    config = {
        "label_y": "RETURN_OO_1",
        "split_date": datetime(2021, 1, 1),
        "batch_size": 50,
        "mu": 100,
        "lambda": 100,
        "hof_size": 100
    }
    generator = GPDeapGenerator(config)
    pop, logbook, hof = generator.run(input_data, n_gen=10, n_pop=500)
"""

import operator
import pickle
import time
from datetime import datetime
from itertools import count
from pathlib import Path
from typing import Any, Dict, List, Tuple, Union, Sequence

import numpy as np
import polars as pl
from deap import base, creator, gp, tools
from deap.gp import PrimitiveTree
from expr_codegen.tool import ExprTool
from loguru import logger
import more_itertools
import polars.selectors as cs

from alpha.data_provider import DataProvider
# å¯¼å…¥æ‰“è¿‡è¡¥ä¸çš„ç»„ä»¶å’ŒåŸºç¡€å·¥å…·
from alpha.gp.base import population_to_exprs, filter_exprs, print_population
# from alpha.gp.cs.helper import batched_exprs, fill_fitness
from alpha.gp.base import RET_TYPE, Expr
from alpha.gp.ea import eaMuPlusLambda_NSGA2
from alpha.polars.utils import CUSTOM_OPERATORS
from alpha.utils.config import settings

from typing import TypeVar
from polars import DataFrame as _pl_DataFrame
from polars import LazyFrame as _pl_LazyFrame

from alpha.utils.schema import F

DataFrame = TypeVar("DataFrame", _pl_LazyFrame, _pl_DataFrame)



class GPDeapGenerator(object):
    """
    é—ä¼ ç¼–ç¨‹å› å­ç”Ÿæˆå™¨

    ä½¿ç”¨ DEAP æ¡†æ¶å®ç°çš„è‡ªåŠ¨åŒ–å› å­æŒ–æ˜å¼•æ“ã€‚

    Attributes:
        config (Dict): é…ç½®å‚æ•°å­—å…¸
        label_y (str): ç›®æ ‡æ ‡ç­¾åˆ—å
        split_date (datetime): è®­ç»ƒ/æµ‹è¯•é›†åˆ†å‰²æ—¥æœŸ
        batch_size (int): æ‰¹é‡è®¡ç®—å¤§å°
        save_dir (Path): ç»“æœä¿å­˜ç›®å½•
        mu (int): ç§ç¾¤ä¿ç•™è§„æ¨¡
        lambda_ (int): æ¯ä»£ç”Ÿæˆåä»£è§„æ¨¡
        hof_size (int): åäººå ‚å¤§å°
    """

    def __init__(self, config: Dict[str, Any] = {}) -> None:
        """
        åˆå§‹åŒ– GP å› å­ç”Ÿæˆå™¨

        Args:
            config: é…ç½®å­—å…¸ï¼Œæ”¯æŒçš„é”®ï¼š
                - label_y (str): ç›®æ ‡åˆ—åï¼Œé»˜è®¤ "RETURN_OO_1"
                - split_date (datetime): åˆ†å‰²æ—¥æœŸï¼Œé»˜è®¤ 2021-01-01
                - batch_size (int): æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ 50
                - mu (int): è¿›åŒ–ç®—æ³•çš„ mu å‚æ•°ï¼Œé»˜è®¤ 100
                - lambda (int): è¿›åŒ–ç®—æ³•çš„ lambda å‚æ•°ï¼Œé»˜è®¤ 100
                - hof_size (int): åäººå ‚å¤§å°ï¼Œé»˜è®¤ 100

        Raises:
            ValueError: å¦‚æœé…ç½®å‚æ•°æ— æ•ˆ
        """
        # --- 1. åŸºç¡€ä¿¡æ¯é…ç½® ---
        self.config = config
        self.name = config.get("name", self.__class__.__name__)

        # --- 2. æ•°æ®ä¸æ—¥æœŸé…ç½® ---
        self.start_date = config.get("start_date", "20190101")
        self.end_date = config.get("end_date", "20241231")
        self.split_date = config.get("split_date", None)
        # å¤šç›®æ ‡ä¼˜åŒ–åç§°
        self.opt_names = config.get("opt_names",("ic", "ir",'complexity'))  #
        self.opt_weights = config.get("opt_weights",(1.0, 1.0,-0.01))  # å¤šç›®æ ‡ä¼˜åŒ–æƒé‡
        # æ•´ä½“ç§ç¾¤fitnesså‡½æ•°,è¾“å…¥å‚æ•°ä¸º:df,factors,split_date,å…¶å®ƒå‚æ•°é‡‡ç”¨é»˜è®¤å
        self.fitness_population_func = config.get("fitness_population_func", None)

        self.pool_func = config.get("pool_func", None)  # è‚¡ç¥¨æ± å‡½æ•°
        self.label_func = config.get("label_func", None)  # æ ‡ç­¾è®¡ç®—å‡½æ•°
        self.random_window_func = config.get("random_window_func", None)  # éšæœºçª—å£å‡½æ•°
        self.extra_terminal_func = config.get("extra_terminal_func", [])  # é¢å¤–ç»ˆç«¯å› å­è®¡ç®—å‡½æ•°

        self.terminals = config.get('terminals', [])  # ç»ˆç«¯å› å­åˆ—è¡¨


        # --- 3. æ ‡ç­¾è®¡ç®—é…ç½® ---
        self.label_window = config.get("label_window", 1) # è®¡ç®—æ ‡ç­¾çš„æœªæ¥çª—å£å¤§å°
        self.label_y = config.get("label_y", f"LABEL_OO_{self.label_window}")  # ç›®æ ‡æ ‡ç­¾åˆ—å,å½“å‰ä»…æ”¯æŒ OPEN-OPEN æ”¶ç›Šç‡

        # --- 4. è¿›åŒ–ç®—æ³•è¶…å‚æ•° ---
        self.mu = config.get("mu", 400) # ç§ç¾¤ä¿ç•™è§„æ¨¡
        self.lambda_ = config.get("lambda", 400)  # æ¯ä»£ç”Ÿæˆåä»£è§„æ¨¡
        self.cxpb = config.get("cxpb", 0.6)  # äº¤å‰æ¦‚ç‡
        self.mutpb = config.get("mutpb", 0.2)  # å˜å¼‚æ¦‚ç‡
        self.hof_size = config.get("hof_size", 1000) # åäººå ‚å¤§å°
        self.batch_size = config.get("batch_size", 200) # æ‰¹å¤„ç†å¤§å°
        self.max_height = config.get("max_height", 6) # æœ€å¤§æ ‘é«˜é™åˆ¶
        # è·¯å¾„è®¾ç½®
        self.save_dir = Path(settings.GP_DEAP_DIR)/ self.name
        self.save_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"âœ“ GP ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ | æ ‡ç­¾: {self.label_y} | æ‰¹å¤§å°: {self.batch_size}")


    def _build_pset(self) -> gp.PrimitiveSetTyped:
        """
        ç²¾ç®€ç‰ˆç®—å­é›†ï¼šä¸“ä¸º LightGBM/ElasticNet ç‰¹å¾å·¥ç¨‹è®¾è®¡
        æ‰€æœ‰ç®—å­å‡è¿”å›æ•°å€¼ç±»å‹ï¼Œç§»é™¤äº†å¯¼è‡´ SchemaError çš„é€»è¾‘ç®—å­
        """
        # ç›´æ¥ä½¿ç”¨ Expr ä½œä¸ºæ ‡è¯†ï¼Œé»˜è®¤å³ä¸ºæµ®ç‚¹æ•°åºåˆ—
        pset = gp.PrimitiveSetTyped("MAIN", [], Expr)
        return pset

    def build_toolbox(self, input_data: pl.LazyFrame) -> base.Toolbox:
        """
        æ„å»ºè¿›åŒ–å·¥å…·ç®±

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œç”¨äºé€‚åº”åº¦è¯„ä¼°

        Returns:
            base.Toolbox: DEAP å·¥å…·ç®±å®ä¾‹
        """
        creator.create("FitnessMulti", base.Fitness, weights=self.opt_weights)
        creator.create("Individual", PrimitiveTree, fitness=creator.FitnessMulti)

        toolbox = base.Toolbox()

        # æ ‘ç”Ÿæˆç®—æ³•: åŠæ•°åŠèŒæ³• (Half and Half)
        toolbox.register("expr", gp.genHalfAndHalf, pset=self.pset, min_=2, max_=5)
        toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)

        # é—ä¼ ç®—å­: é”¦æ ‡èµ›é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
        toolbox.register("select", tools.selTournament, tournsize=3) # å•ç›®æ ‡ä¼˜åŒ–é€‰æ‹©
        # toolbox.register("select", tools.selNSGA2)  # å¤šç›®æ ‡ä¼˜åŒ–é€‰æ‹©

        toolbox.register("mate", gp.cxOnePoint)
        toolbox.register("expr_mut", gp.genFull, min_=0, max_=2)
        toolbox.register("mutate", gp.mutUniform, expr=toolbox.expr_mut, pset=self.pset)

        # é™åˆ¶æ ‘é«˜ï¼Œé˜²æ­¢è†¨èƒ€ (Bloat)
        toolbox.decorate("mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=self.max_height))
        toolbox.decorate("mutate", gp.staticLimit(key=operator.attrgetter("height"), max_value=self.max_height))

        # æ ¸å¿ƒï¼šæ‰¹é‡è¯„ä¼°æ˜ å°„
        toolbox.register("evaluate", lambda x: (np.nan, np.nan))  # å®é™…è¯„åˆ†åœ¨ map ä¸­å®Œæˆ
        toolbox.register(
            "map",
            self.map_exprs,
            gen=count(),
            label=self.label_y,
            split_date=self.split_date,
            input_data=input_data
        )

        logger.debug("âœ“ Toolbox æ„å»ºå®Œæˆ")
        return toolbox

    def map_exprs(
        self,
        evaluate_func: Any,
        individuals: List,
        gen,
        label: str,
        split_date: datetime,
        input_data: pl.DataFrame
    ) -> List[Tuple[float, float]]:
        """
        æ‰¹é‡è®¡ç®—ç§ç¾¤é€‚åº”åº¦çš„æ ¸å¿ƒæ–¹æ³•

        å¤„ç†æµç¨‹ï¼š
        1. å¤‡ä»½å½“å‰ä»£çš„è¡¨è¾¾å¼
        2. åŠ è½½å†å²é€‚åº”åº¦ç¼“å­˜
        3. æå–å¹¶è¿‡æ»¤è¡¨è¾¾å¼
        4. æ‰¹é‡è®¡ç®—æ–°è¡¨è¾¾å¼çš„é€‚åº”åº¦
        5. æ›´æ–°ç¼“å­˜å¹¶è¿”å›ç»“æœ

        Args:
            evaluate_func: è¯„ä¼°å‡½æ•°ï¼ˆæœªä½¿ç”¨ï¼Œç”± map è°ƒç”¨è¦æ±‚ï¼‰
            individuals: å½“å‰ä»£çš„ä¸ªä½“åˆ—è¡¨
            gen: ä»£æ•°è¿­ä»£å™¨
            label: æ ‡ç­¾åˆ—å
            split_date: è®­ç»ƒ/æµ‹è¯•åˆ†å‰²æ—¥æœŸ
            input_data: è¾“å…¥æ•°æ®

        Returns:
            List[Tuple[float, float]]: æ¯ä¸ªä¸ªä½“çš„é€‚åº”åº¦å…ƒç»„åˆ—è¡¨
        """
        g = next(gen)
        logger.info(f">>> ç¬¬ {g} ä»£ | ç§ç¾¤å¤§å°: {len(individuals)}")

        # 2. ç¼“å­˜ç®¡ç†
        cache_path = self.save_dir / 'fitness_cache.pkl'
        fitness_results: Dict = {} # è¡¨è¾¾å¼å­—ç¬¦ä¸² -> é€‚åº”åº¦å…ƒç»„
        if cache_path.exists():
            try:
                with open(cache_path, 'rb') as f:
                    fitness_results = pickle.load(f)
                logger.debug(f"âœ“ åŠ è½½å†å²ç¼“å­˜ | å·²æœ‰ç»“æœ: {len(fitness_results)}")
            except Exception as e:
                logger.warning(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")

        # 3. è¡¨è¾¾å¼æ¸…æ´—ä¸è¿‡æ»¤
        logger.debug("ğŸ”„ è½¬æ¢ DEAP æ ‘ -> Sympy è¡¨è¾¾å¼...")
        exprs_list = population_to_exprs(individuals, globals().copy())
        exprs_to_calc = filter_exprs(exprs_list, self.pset, RET_TYPE, fitness_results)

        logger.info(f"ğŸ“Š éœ€è®¡ç®—: {len(exprs_to_calc)} / {len(exprs_list)} ä¸ªè¡¨è¾¾å¼")

        # 4. æ‰¹é‡è®¡ç®—
        if len(exprs_to_calc) > 0:
            for batch_id, batch in enumerate(more_itertools.batched(exprs_to_calc, self.batch_size)):
                logger.debug(f"  æ‰¹æ¬¡ {batch_id + 1} | å¤§å°: {len(list(batch))}")
                new_scores = self.batched_exprs(batch_id, list(batch), g, label, split_date, input_data)
                fitness_results.update(new_scores)

            # æ›´æ–°å…¨å±€ç¼“å­˜
            try:
                with open(cache_path, 'wb') as f:
                    pickle.dump(fitness_results, f)
                logger.debug(f"âœ“ ç¼“å­˜å·²æ›´æ–° | æ€»ç»“æœæ•°: {len(fitness_results)}")
            except Exception as e:
                logger.warning(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

        # 5. å›å¡«é€‚åº”åº¦
        fitness_values = self.fill_fitness(individuals,exprs_list, fitness_results)
        logger.info(f"âœ“ ç¬¬ {g} ä»£è¯„ä¼°å®Œæˆ")
        return fitness_values

    def build_statistics(self) -> tools.Statistics:
        """
        å®šä¹‰è¿›åŒ–è¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ç›‘æ§æŒ‡æ ‡

        Returns:
            tools.Statistics: DEAP ç»Ÿè®¡å¯¹è±¡
        """
        stats = tools.Statistics(lambda ind: ind.fitness.values)
        stats.register("avg", np.nanmean, axis=0)
        stats.register("max", np.nanmax, axis=0)
        stats.register("min", np.nanmin, axis=0)
        stats.register("std", np.nanstd, axis=0)
        return stats

    def run(
        self,
        n_gen: int = 10,
        n_pop: int = 1000
    ) -> Tuple[List, Any, tools.HallOfFame]:
        """
        å¯åŠ¨è¿›åŒ–æµç¨‹

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œå¿…é¡»åŒ…å«æ ‡ç­¾åˆ—
            n_gen: è¿›åŒ–ä»£æ•°ï¼Œé»˜è®¤ 10
            n_pop: åˆå§‹ç§ç¾¤å¤§å°ï¼Œé»˜è®¤ 1000

        Returns:
            Tuple: (æœ€ç»ˆç§ç¾¤, è¿›åŒ–æ—¥å¿—, åäººå ‚)

        Raises:
            ValueError: å¦‚æœè¾“å…¥æ•°æ®æ— æ•ˆ
        """
        # 2. è½½å…¥åŸå§‹æ•°æ®
        # æŒ–æ˜å› å­é€šå¸¸éœ€è¦ OHLCVï¼Œè®¡ç®— OO æ”¶ç›Šç‡éœ€è¦ OPEN
        input_data = DataProvider().load_data(
            start_date=self.start_date,
            end_date=self.end_date,
            funcs=[self.pool_func, self.label_func, self.extra_terminal_func],
            select_cols=[F.POOL_MASK, self.label_y, *self.terminals],
            cache_path=self.save_dir / f"{self.label_y}.parquet"
        )
        logger.info("ğŸ’¾ æ ‡ç­¾æ•°æ®å·²å°±ç»ª")

        logger.info(f"ğŸš€ å¯åŠ¨ GP è¿›åŒ– | ä»£æ•°: {n_gen} | ç§ç¾¤: {n_pop}")
        self.pset = self._build_pset()
        toolbox = self.build_toolbox(input_data)
        stats = self.build_statistics()
        hof = tools.HallOfFame(self.hof_size)

        # åˆå§‹åŒ–ç§ç¾¤
        pop = toolbox.population(n=n_pop)
        logger.info(f"âœ“ åˆå§‹ç§ç¾¤å·²ç”Ÿæˆ | å¤§å°: {len(pop)}")

        # æ‰§è¡Œè¿›åŒ–
        logger.info("â–¶ï¸ å¼€å§‹é—ä¼ ç¼–ç¨‹è¿›åŒ–...")
        pop, logbook = eaMuPlusLambda_NSGA2(
            pop, toolbox,
            mu=self.mu,
            lambda_=self.lambda_,
            cxpb= self.cxpb,  # äº¤å‰æ¦‚ç‡
            mutpb= self.mutpb,  # å˜å¼‚æ¦‚ç‡
            ngen=n_gen,
            stats=stats,
            halloffame=hof,
            verbose=True
        )

        # ä¿å­˜åäººå ‚
        hof_path = self.save_dir / 'best_hof.pkl'
        try:
            with open(hof_path, 'wb') as f:
                pickle.dump(hof, f)
            logger.info(f"ğŸ’¾ åäººå ‚å·²ä¿å­˜è‡³: {hof_path}")
        except Exception as e:
            logger.error(f"âŒ åäººå ‚ä¿å­˜å¤±è´¥: {e}")

        logger.info(f"âœ¨ GP è¿›åŒ–å®Œæˆ | æœ€ç»ˆç§ç¾¤: {len(pop)} | åäººå ‚: {len(hof)}")

        print('=' * 60)
        print(logbook)

        print('=' * 60)
        print_population(hof, globals().copy())
        self.export_hof_to_csv(hof, globals().copy())
        return pop, logbook, hof

    def export_hof_to_csv(self, hof, globals_, filename="best_factors.csv"):
        """
        å°†åäººå ‚å†…å®¹å¯¼å‡ºåˆ° CSV

        Args:
            hof: åäººå ‚å¯¹è±¡
            globals_: å…¨å±€å‘½åç©ºé—´ globals()
            filename: è¾“å‡ºæ–‡ä»¶å
        """
        import pandas as pd
        # exprs_list å¾—åˆ°çš„æ˜¯ (ç®€åŒ–å k, è¡¨è¾¾å¼æ–‡æœ¬ v, å¤æ‚åº¦ c)
        exprs_list = population_to_exprs(hof, globals_)
        data = []
        for (k, v, c), ind in zip(exprs_list, hof):
            kvs = {
                "factor_name": k,  # å› å­ç®€åŒ–å
                "expression": v,  # ç®€åŒ–åçš„è¡¨è¾¾å¼æ–‡æœ¬ (v)
                "complexity": c,  # å¤æ‚åº¦ (c)
                "raw_tree": str(ind),  # åŸå§‹ DEAP æ ‘ç»“æ„
            }
            # æå–åäººå ‚ä¸ªä½“çš„é€‚åº”åº¦å€¼å¹¶å­˜å‚¨åˆ°å­—å…¸ä¸­
            for name, value in zip(self.opt_names, ind.fitness.values):
                kvs[name] = value
            data.append(kvs)

        # 2. è½¬æ¢ä¸º DataFrame å¹¶ä¿å­˜
        df = pd.DataFrame(data)
        output_path = self.save_dir / filename
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        logger.info(f"âœ… åäººå ‚å› å­å·²å¯¼å‡ºè‡³ CSV: {output_path}")
        return df

    def fitness_individual(self,a: str, b: str) -> pl.Expr:
        """ä¸ªä½“fitnesså‡½æ•°"""
        return pl.corr(a, b, method='spearman', ddof=0, propagate_nans=False)

    def batched_exprs(self, batch_id, exprs_list, gen, label, split_date, df_input):
        """æ¯ä»£ç§ç¾¤åˆ†æ‰¹è®¡ç®—ï¼ŒåŒ…å«è¯¦ç»†æ€§èƒ½æ—¥å¿—åŠå¹³å‡ç”¨æ—¶"""
        if len(exprs_list) == 0:
            return {}

        tool = ExprTool()
        codes, G = tool.all(exprs_list, style='polars', template_file='template.py.j2',
                            replace=False, regroup=True, format=True,
                            date='DATE', asset='ASSET', over_null=None,
                            skip_simplify=True)

        cnt = len(exprs_list)
        globals_ = {**CUSTOM_OPERATORS}
        exec(codes, globals_)

        # --- é˜¶æ®µ A: å› å­å€¼è®¡ç®— ---
        logger.info("ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šå¼€å§‹è®¡ç®—å› å­å€¼ (å…± {} æ¡)", gen, batch_id, cnt)
        tic_calc = time.perf_counter()

        df_output = globals_['main'](df_input.lazy(), ge_date_idx=0).collect()

        toc_calc = time.perf_counter()
        calc_duration = toc_calc - tic_calc

        # æ—¥å¿—è¾“å‡ºï¼šæ·»åŠ é€Ÿåº¦å’Œå¹³å‡è€—æ—¶
        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šè®¡ç®—å®Œæˆã€‚æ€»è€—æ—¶: {:.3f}s | é€Ÿåº¦: {:.2f} æ¡/s | å¹³å‡: {:.4f}s/æ¡",
            gen, batch_id, calc_duration, cnt / calc_duration, calc_duration / cnt
        )

        # --- é˜¶æ®µ B: é€‚åº”åº¦è®¡ç®— ---
        logger.info("ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šå¼€å§‹èšåˆ IC/IR æŒ‡æ ‡", gen, batch_id)
        tic_fit = time.perf_counter()

        fitness_df = self.fitness_population(
            df_output,
            columns=[k for k, v, c in exprs_list],
            label=label,
            split_date=split_date
        )

        toc_fit = time.perf_counter()
        fit_duration = toc_fit - tic_fit

        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šèšåˆå®Œæˆã€‚è€—æ—¶: {:.3f}s | å¹³å‡: {:.4f}s/æ¡",
            gen, batch_id, fit_duration, fit_duration / cnt
        )

        # 3. ç»“æœè½¬æ¢
        key_to_expr = {k: str(v) for k, v, c in exprs_list}
        new_results = {
            key_to_expr[row.pop("column")]: row
            for row in fitness_df.to_dicts()
        }

        # 4. æ±‡æ€»
        total_dur = calc_duration + fit_duration
        logger.info(
            "ç¬¬{}ä»£-ç¬¬{}æ‰¹ï¼šæµç¨‹ç»“æŸã€‚æ€»è®¡: {:.3f}s | æ€»å¹³å‡: {:.4f}s/æ¡ (ç®—å€¼:{:.1%}, æŒ‡æ ‡:{:.1%})",
            gen, batch_id, total_dur, total_dur / cnt, calc_duration / total_dur, fit_duration / total_dur
        )

        return new_results

    def fitness_population(self, df: Union[pl.DataFrame, pl.LazyFrame], columns: Sequence[str], label: str,
                           split_date: datetime = None) -> pl.DataFrame:
        if df is None:
            return pl.DataFrame()

        lf = df.lazy() if isinstance(df, pl.DataFrame) else df

        # è®¡ç®—æ¯æ—¥ IC
        lf_ic = (
            lf.select(["DATE", label, *columns])
            .with_columns(cs.numeric().cast(pl.Float64))
            .group_by('DATE')
            .agg([pl.corr(col, label, method='spearman').alias(col) for col in columns])
        )

        # æ ‡è®°æ•°æ®é›†ï¼šä¿®å¤è­¦å‘Šçš„æ ¸å¿ƒé€»è¾‘
        if split_date is not None:
            # åªæœ‰ split_date ä¸ä¸º None æ—¶æ‰è¿›è¡Œåˆ—å¯¹æ¯”
            lf_ic = lf_ic.with_columns(
                pl.when(pl.col("DATE") < split_date)
                .then(pl.lit("train"))
                .otherwise(pl.lit("valid"))
                .alias("dataset")
            )
        else:
            lf_ic = lf_ic.with_columns(pl.lit("all").alias("dataset"))

        # èšåˆç»Ÿè®¡æŒ‡æ ‡
        lf_stats = (
            lf_ic.group_by("dataset")
            .agg([
                pl.when(cs.numeric().null_count() / pl.len() <= 0.5)
                .then(cs.numeric().mean())
                .otherwise(None).name.suffix("_ic"),
                (cs.numeric().mean() / cs.numeric().std(ddof=0)).name.suffix("_ir")
            ])
        )

        # è½¬æ¢ç»“æ„ï¼šå…ˆ collect é¿å… LazyFrame.pivot å…¼å®¹æ€§é—®é¢˜
        summary_df = lf_stats.collect()

        final_df = (
            summary_df.unpivot(index="dataset", variable_name="raw", value_name="value")
            .with_columns([
                pl.col("raw").str.extract(r"^(.*)_(ic|ir)$", 1).alias("column"),
                pl.col("raw").str.extract(r"^(.*)_(ic|ir)$", 2).alias("metric")
            ])
            .with_columns(
                pl.when(pl.col("dataset") != "all")
                .then(pl.format("{}_{}", pl.col("metric"), pl.col("dataset")))
                .otherwise(pl.col("metric"))
                .alias("final_metric")
            )
            .pivot(index="column", on="final_metric", values="value")
        )

        return final_df

    def fill_fitness(self, individuals, exprs_old, fitness_results):
        """
        æ ¹æ®æƒ¯ä¾‹å¤„ç†å¹¶è¿”å› Fitness å…ƒç»„åˆ—è¡¨ã€‚
        åŒæ—¶åŸåœ°æ›´æ–°ä¸ªä½“çš„ stats å±æ€§ã€‚

        Args:
            individuals: DEAP ä¸ªä½“åˆ—è¡¨ [ind1, ind2, ...]
            exprs_old: è¾…åŠ©ä¿¡æ¯ [(k, v, c), ...]ï¼Œå…¶ä¸­ v æ˜¯è¡¨è¾¾å¼å¯¹è±¡æˆ–å­—ç¬¦ä¸²
            fitness_results: è®¡ç®—ç»“æœå­—å…¸ {str(v): {metrics_dict}}

        Returns:
            List[Tuple]: å¯¹åº”æ¯ä¸ªä¸ªä½“çš„é€‚åº”åº¦å…ƒç»„åˆ—è¡¨ï¼Œä¾‹å¦‚ [(ic, ir, comp), ...]
        """
        # 0. é•¿åº¦å®‰å…¨æ€§æ£€æŸ¥
        if len(individuals) != len(exprs_old):
            raise ValueError(f"æ•°æ®å¯¹é½å¤±è´¥: individuals({len(individuals)}) != exprs_old({len(exprs_old)})")

        # 1. é¢„è®¡ç®—æƒ©ç½šå‘é‡ (æ ¹æ® opt_weights ç¬¦å·ç¡®å®šæƒ©ç½šæ–¹å‘)
        # è‹¥æƒé‡ä¸ºæ­£(æ±‚æœ€å¤§)ï¼Œæƒ©ç½šå€¼ä¸º 0.0ï¼›è‹¥æƒé‡ä¸ºè´Ÿ(æ±‚æœ€å°)ï¼Œæƒ©ç½šå€¼ä¸º 999.0
        penalty_values = tuple(0.0 if w > 0 else 999.0 for w in self.opt_weights)

        fit_tuples_list = []

        # 2. éå†ä¸ªä½“ä¸å¯¹åº”çš„è¡¨è¾¾å¼æè¿°
        for ind, (_, v, _) in zip(individuals, exprs_old):
            # ç»Ÿä¸€ä½¿ç”¨å­—ç¬¦ä¸²é”®åŒ¹é…ç»“æœå­—å…¸
            search_key = str(v)
            score_dict = fitness_results.get(search_key)

            # æƒ…å†µ A: åŒ¹é…å¤±è´¥ (è¯¥å› å­å› éæ³•ã€é‡å¤è¢«è¿‡æ»¤ï¼Œæˆ–è®¡ç®—æ¨¡å—æŠ¥é”™)
            if score_dict is None:
                fit_tuples_list.append(penalty_values)
                ind.stats = None  # æ¸…ç©ºæˆ–åˆå§‹åŒ– stats
                continue

            # æƒ…å†µ B: åŒ¹é…æˆåŠŸï¼Œæ ¹æ® self.opt_names æå–æŒ‡æ ‡
            try:
                current_fit = []
                for i, name in enumerate(self.opt_names):
                    if name == "complexity":
                        # ç›´æ¥è·å– DEAP æ ‘çš„èŠ‚ç‚¹æ•°ä½œä¸ºå¤æ‚åº¦
                        val = float(len(ind))
                    else:
                        # ä»ç»“æœå­—å…¸æå–æŒ‡æ ‡ï¼Œè‹¥ Key ä¸å­˜åœ¨åˆ™ç›´æ¥è§¦å‘ KeyError (é…ç½®é”™è¯¯)
                        try:
                            raw_val = score_dict[name]

                            # æ ¸å¿ƒé˜²å¾¡ï¼šå¤„ç†è®¡ç®—ç»“æœä¸­çš„ NaN æˆ– Infï¼Œé˜²æ­¢ Logbook å´©æºƒ
                            if raw_val is None or not np.isfinite(raw_val):
                                val = penalty_values[i]
                            else:
                                val = float(raw_val)
                        except KeyError:
                            logger.error(f"âŒ æŒ‡æ ‡é…ç½®é”™è¯¯: '{name}' ä¸åœ¨è®¡ç®—ç»“æœä¸­!")
                            logger.error(f"å½“å‰å¯ç”¨æŒ‡æ ‡: {list(score_dict.keys())}")
                            raise KeyError(f"Metric '{name}' missing in fitness_results.")

                    current_fit.append(val)

                # è½¬æ¢ä¸ºå…ƒç»„å¹¶å­˜å…¥ç»“æœåˆ—è¡¨
                fit_tuple = tuple(current_fit)
                fit_tuples_list.append(fit_tuple)

                # åŸåœ°æŒ‚è½½å…¨é‡æŒ‡æ ‡å­—å…¸ï¼Œæ–¹ä¾¿åéªŒåˆ†æ
                ind.stats = score_dict

            except Exception as e:
                logger.error(f"å¤„ç†ä¸ªä½“é€‚åº”åº¦å¼‚å¸¸: {e} | è¡¨è¾¾å¼: {search_key}")
                fit_tuples_list.append(penalty_values)
                ind.stats = None

        return fit_tuples_list
