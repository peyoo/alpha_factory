import polars.selectors as cs
from typing import List, Union
import polars as pl
from loguru import logger
import time
from alpha.utils.schema import F

def batch_calc_factor_turnover(
        df: Union[pl.DataFrame, pl.LazyFrame],
        factors: Union[str, List[str]] = r"^factor_.*",
        date_col: str = F.DATE,
        asset_col: str = F.ASSET,
        lag: int = 1
) -> pl.DataFrame:
    """
    å¤§æ‰¹é‡è®¡ç®—å› å­çš„æˆªé¢è‡ªç›¸å…³æ€§ï¼Œç”¨äºä¼°ç®—å› å­æ¢æ‰‹ç‡å’Œé€»è¾‘ç¨³å®šæ€§ã€‚

    è®¡ç®—é€»è¾‘ï¼š
    1. **æ»åå¯¹é½**ï¼šæŒ‰èµ„äº§ï¼ˆASSETï¼‰å¯¹å› å­å€¼è¿›è¡Œä½ç§»ï¼ˆshiftï¼‰ï¼Œè·å–å‰ T æœŸçš„å› å­å€¼ã€‚
    2. **æ¯æ—¥è®¡ç®—**ï¼šåœ¨æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆDATEï¼‰æˆªé¢ä¸Šï¼Œè®¡ç®—å½“å‰å› å­å€¼ä¸æ»åå› å­å€¼çš„ Rank ç›¸å…³æ€§ï¼ˆSpearmanï¼‰ã€‚
    3. **èšåˆç»Ÿè®¡**ï¼šè®¡ç®—å…¨æ—¶æ®µè‡ªç›¸å…³æ€§çš„å‡å€¼ã€‚è‡ªç›¸å…³æ€§è¶Šæ¥è¿‘ 1ï¼Œå› å­è¶Šç¨³å®šï¼Œæ¢æ‰‹è¶Šä½ã€‚

    Returns:
        pl.DataFrame: å› å­ç¨³å®šæ€§ç»Ÿè®¡è¡¨ã€‚
        | åˆ—å | ç±»å‹ | è¯´æ˜ |
        | :--- | :--- | :--- |
        | factor | String | å› å­åç§° |
        | avg_autocorr | Float64 | å› å­å€¼åºåˆ—çš„å¹³å‡æˆªé¢è‡ªç›¸å…³ç³»æ•° (è¶Šæ¥è¿‘ 1 è¶Šç¨³å®š) |
        | turnover_estimate | Float64 | æ¢æ‰‹ç‡ä¼°ç®—å€¼ (1 - avg_autocorr)ï¼Œç”¨äºæƒ©ç½šé«˜é¢‘å› å­ |
    """
    start_time = time.perf_counter()
    lf = df.lazy() if isinstance(df, pl.DataFrame) else df

    # --- 1. è‡ªåŠ¨è·å–å› å­åˆ— ---
    f_selector = cs.matches(factors) if isinstance(factors, str) else cs.by_name(factors)
    try:
        factor_cols = lf.select(f_selector).collect_schema().names()
    except Exception as e:
        logger.error(f"âŒ å› å­é€‰æ‹©å™¨åŒ¹é…å¤±è´¥: {e}")
        return pl.DataFrame()

    if not factor_cols:
        logger.warning(f"âš ï¸ æ— æ³•åŒ¹é…åˆ°ä»»ä½•å› å­ (æ¨¡å¼: {factors})ï¼Œè¿”å›ç©ºç»“æœã€‚")
        return pl.DataFrame()

    logger.info(f"ğŸ”„ å¼€å§‹è®¡ç®— {len(factor_cols)} ä¸ªå› å­çš„è‡ªç›¸å…³æ€§ (Lag={lag})")

    # --- 2. æ ¸å¿ƒè®¡ç®—é“¾è·¯ ---
    # åˆ©ç”¨ Polars çš„ over() çª—å£å‡½æ•°å®ç°é«˜æ•ˆçš„ä¸ªè‚¡æ»åå¯¹é½
    try:
        turnover_stats = (
            lf.select([date_col, asset_col] + factor_cols)
            .with_columns([
                pl.col(f).shift(lag).over(asset_col).alias(f"{f}_lag")
                for f in factor_cols
            ])
            .group_by(date_col)
            .agg([
                # è®¡ç®— Spearman ç›¸å…³æ€§ (é€šè¿‡å¯¹ Rank åçš„å€¼è®¡ç®— Pearson å®ç°)
                pl.corr(pl.col(f).rank(), pl.col(f"{f}_lag").rank(), method="pearson").alias(f)
                for f in factor_cols
            ])
            # å°†å®½è¡¨è½¬ä¸ºé•¿è¡¨ï¼š[DATE, factor, autocorr]
            .unpivot(index=date_col, on=factor_cols, variable_name="factor", value_name="autocorr")
            .group_by("factor")
            .agg([
                # è¿‡æ»¤æ‰æ— æ³•è®¡ç®—è‡ªç›¸å…³çš„æ—¥æœŸï¼ˆå¦‚å…¨åœç‰Œæˆ–åˆå§‹å‡ æ—¥ï¼‰
                pl.col("autocorr").filter(pl.col("autocorr").is_not_nan()).mean().alias("avg_autocorr")
            ])
            .with_columns([
                # æ¢æ‰‹ç‡ä¼°ç®—ï¼š1 - å¹³å‡è‡ªç›¸å…³ã€‚
                # æ³¨æ„ï¼šè¿™åªæ˜¯ä¸€ä¸ªçº¿æ€§ä¼°ç®—ï¼Œå®ç›˜æ¢æ‰‹è¿˜å—æŒä»“æƒé‡çš„éçº¿æ€§æ˜ å°„å½±å“ã€‚
                (1 - pl.col("avg_autocorr")).alias("turnover_estimate")
            ])
            .collect()
        )

        duration = time.perf_counter() - start_time
        logger.success(f"âœ… å› å­æ¢æ‰‹ç‡ä¼°ç®—å®Œæˆ | è€—æ—¶: {duration:.2f}s | å› å­æ•°: {len(factor_cols)}")
        return turnover_stats

    except Exception as e:
        logger.exception(f"âŒ è®¡ç®—å› å­è‡ªç›¸å…³æ—¶å´©æºƒ: {e}")
        return pl.DataFrame()
