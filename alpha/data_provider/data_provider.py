import polars as pl
import polars.selectors as cs
from pathlib import Path
from loguru import logger
from typing import Optional, List
from datetime import date, datetime

from alpha.utils.config import settings


class DataProvider:
    """
    æ•°æ®è¯»å–æ¥å£ (L4 å±‚)

    èŒè´£:
    - ç»Ÿä¸€å…¥å£: å¯¹å¤–éšè—æŒ‰å¹´å­˜å‚¨çš„ç‰©ç†ç»†èŠ‚ï¼Œæ”¯æŒè·¨å¹´æ•°æ®æ— ç¼æ‹¼æ¥ã€‚
    - æ€§èƒ½ä¼˜åŒ–: æ·±åº¦é›†æˆ Polars çš„å»¶è¿ŸåŠ è½½æœºåˆ¶ï¼Œå®ç°ç£ç›˜åˆ°å†…å­˜çš„æœ€å°åŒ–ä¼ è¾“ã€‚
    - èµ„äº§ç­›é€‰: æ”¯æŒåœ¨åŠ è½½é˜¶æ®µé€šè¿‡ is_in ç®—å­ç›´æ¥ä¸‹å‹è¿‡æ»¤èµ„äº§æ± ã€‚
    """

    def __init__(self):
        self.warehouse_dir = Path(settings.WAREHOUSE_DIR)
        self.factor_dir = self.warehouse_dir / "unified_factors"
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.factor_dir.mkdir(parents=True, exist_ok=True)
        logger.debug(f"âœ“ DataProvider åˆå§‹åŒ–å®Œæˆ | ä»“åº“è·¯å¾„: {self.factor_dir}")


    def _prepare_labeled_data(self) -> pl.DataFrame:
        """
        ä» DataProvider è·å–æ•°æ®å¹¶è®¡ç®—æŒ–æ˜æ ‡ç­¾
        è®¡ç®—é€»è¾‘ï¼šæœªæ¥ N æ—¥çš„ Open-to-Open æ”¶ç›Šç‡
        """

        cache_file = self.save_dir / f"labeled_{self.label_y}.parquet"

        data_provider = DataProvider()

        if not self.overwrite and cache_file.exists():
            logger.info(f"ğŸ“‚ å‘ç°æ ‡ç­¾æ•°æ®ç¼“å­˜ï¼Œç›´æ¥åŠ è½½: {cache_file}")
            return pl.read_parquet(cache_file)

        logger.info(f"ğŸ“¡ æ­£åœ¨è®¡ç®—æ ‡ç­¾ '{self.label_y}'...")


        # 2. è½½å…¥åŸå§‹æ•°æ®
        # æŒ–æ˜å› å­é€šå¸¸éœ€è¦ OHLCVï¼Œè®¡ç®— OO æ”¶ç›Šç‡éœ€è¦ OPEN
        lf = data_provider.load_data(
            start_date= self.start_date,
            end_date=self.end_date,
            columns=["DATE", "ASSET", "OPEN", "CLOSE", "HIGH", "LOW", "VOLUME",'AMOUNT']
        )

        # 3. è®¡ç®—æœªæ¥æ”¶ç›Šç‡ (Label Generation)
        # è®¡ç®—å…¬å¼: (æœªæ¥ç¬¬ N+1 æ—¥å¼€ç›˜ä»· / æœªæ¥ç¬¬ 1 æ—¥å¼€ç›˜ä»·) - 1
        # æ³¨æ„ï¼šOO_1 å®é™…ä¸Šéœ€è¦ shift(-2) å’Œ shift(-1)
        lf = lf.sort(["ASSET", "DATE"]).with_columns([
            (
                    (pl.col("OPEN").shift(-(self.label_window  + 1)).over("ASSET") /
                     pl.col("OPEN").shift(-1).over("ASSET")) - 1
            ).alias(self.label_y)
        ])

        # 4. æˆªé¢ä¸­æ€§åŒ–ä¸å»æå€¼ (Z-Score)
        # è¿™ä¸€æ­¥å°†æ”¶ç›Šç‡è½¬åŒ–ä¸ºâ€œè¯¥è‚¡ç¥¨åœ¨å½“æ—¥å…¨å¸‚åœºä¸­çš„ç›¸å¯¹å¼ºåº¦â€
        date_col = "DATE"
        lf = lf.filter(pl.col(self.label_y).is_not_null()).with_columns([
            (
                    (pl.col(self.label_y) - pl.col(self.label_y).mean().over(date_col))
                    / (pl.col(self.label_y).std().over(date_col) + 1e-6)
            )
            .clip(-3, 3)  # é™åˆ¶åœ¨æ­£è´Ÿ 3 ä¸ªæ ‡å‡†å·®å†…ï¼Œæ¶ˆé™¤å¦–è‚¡å™ªå£°
            .fill_nan(0.0)
            .alias(self.label_y)
        ])
        lf = lf.sort(['ASSET', 'DATE']).with_columns([
            pl.col("ASSET").set_sorted(),
            # å¼ºåˆ¶å°†æ‰€æœ‰æ•°å€¼åˆ—è½¬ä¸º Float64ï¼Œé¿å… GP è¿è¡Œæ—¶ SchemaError
            cs.numeric().cast(pl.Float64)
        ])
        # 5. æ‰§è¡Œè®¡ç®—å¹¶æŒä¹…åŒ–
        df = lf.collect()

        if df.height == 0:
            raise ValueError("è®¡ç®—åæ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ DataProvider è¿”å›ç»“æœæˆ–æ—¥æœŸèŒƒå›´")

        df.write_parquet(cache_file, compression="snappy")
        logger.info(f"ğŸ’¾ æ ‡ç­¾æ•°æ®å·²å°±ç»ª | è¡Œæ•°: {df.height:,} | å‡å€¼: {df[self.label_y].mean():.4f}")

        return df


    def load_data(
            self,
            start_date: str,
            end_date: str,
            assets: Optional[List[str]] = None,
            columns: Optional[List[str]] = None,
            exclude_suspended: bool = False,
            exclude_st: bool = False,
    ) -> pl.LazyFrame:
        """
        åŠ è½½ç»Ÿä¸€å› å­åº“ (Lazy Mode)

        Args:
            start_date: èµ·å§‹æ—¥æœŸ 'YYYYMMDD'
            end_date: æˆªæ­¢æ—¥æœŸ 'YYYYMMDD'
            assets: èµ„äº§åˆ—è¡¨ (ts_code åˆ—è¡¨)ï¼Œä¸ä¼ åˆ™åŠ è½½å…¨å¸‚åœº
            columns: éœ€è¦åŠ è½½çš„ç‰¹å¾åˆ—åï¼Œä¸ä¼ åˆ™åŠ è½½æ‰€æœ‰åˆ—
            exclude_suspended: æ˜¯å¦è¿‡æ»¤æ‰åœç‰Œæ—¥æ•°æ®
            exclude_st: æ˜¯å¦è¿‡æ»¤æ‰ ST çŠ¶æ€æ•°æ®

        Returns:
            pl.LazyFrame: åŒ…å«è®¡ç®—å›¾çš„å»¶è¿Ÿå¯¹è±¡
        """
        try:
            s_dt = datetime.strptime(start_date, "%Y%m%d").date()
            e_dt = datetime.strptime(end_date, "%Y%m%d").date()
        except ValueError as e:
            raise ValueError(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ (éœ€ YYYYMMDD): {e}")

        # 1. åŠ¨æ€è·¯ç”±å¹´åº¦ Parquet æ–‡ä»¶
        scans = []
        for year in range(s_dt.year, e_dt.year + 1):
            file_path = self.factor_dir / f"{year}.parquet"
            if file_path.exists():
                # ğŸ’¡ scan_parquet ä¼šè‡ªåŠ¨è¿›è¡Œ Row Group çº§åˆ«çš„è°“è¯ä¸‹å‹ä¼˜åŒ–
                scans.append(pl.scan_parquet(file_path))
            else:
                logger.warning(f"âš ï¸ å› å­åº“ç¼ºå°‘å¹´åº¦æ•°æ®: {year}")

        if not scans:
            raise FileNotFoundError(f"âŒ åœ¨ {self.factor_dir} ä¸­æœªæ‰¾åˆ° [{start_date} ~ {end_date}] èŒƒå›´å†…çš„ä»»ä½•æ•°æ®")

        # 2. å‚ç›´æ‹¼æ¥å¹´åº¦åˆ†ç‰‡ (Lazy çº§åˆ«)
        lf = pl.concat(scans)

        # 3. è°“è¯ä¸‹å‹ä¼˜åŒ– (Predicate Pushdown)
        # è¿‡æ»¤æ—¥æœŸèŒƒå›´
        lf = lf.filter(pl.col("DATE").is_between(s_dt, e_dt))

        # è¿‡æ»¤èµ„äº§æ± 
        if assets:
            lf = lf.filter(pl.col("ASSET").is_in(assets))

        # çŠ¶æ€è¿‡æ»¤
        if exclude_suspended:
            lf = lf.filter(pl.col("IS_SUSPENDED") is False)

        if exclude_st:
            lf = lf.filter(pl.col("IS_ST") is False)

        # 4. åˆ—æŠ•å½±ä¼˜åŒ– (Projection Pushdown)
        if columns:
            # è‡ªåŠ¨ä¿ç•™ä¸»é”®åˆ—ï¼ˆå»é‡å¤„ç†ï¼‰
            final_cols = list(dict.fromkeys(["DATE", "ASSET"] + columns))
            lf = lf.select(final_cols)

        return lf

    def get_available_dates(self) -> List[date]:
        """è·å–ä»“åº“ä¸­å·²æœ‰çš„æ‰€æœ‰äº¤æ˜“æ—¥æ¸…å•"""
        try:
            # ä»…æ‰«æ DATE åˆ—ï¼Œä¸”åˆ©ç”¨é€šé…ç¬¦æ‰«æå…¨åº“ï¼Œæå…¶é«˜æ•ˆ
            return (
                pl.scan_parquet(self.factor_dir / "*.parquet")
                .select("DATE")
                .collect()
                .unique()
                .sort("DATE")
                .get_column("DATE")
                .to_list()
            )
        except Exception as e:
            logger.error(f"è·å–å¯ç”¨æ—¥æœŸæ¸…å•å¤±è´¥: {e}")
            return []

    def validate_schema(self, lf: pl.LazyFrame) -> bool:
        """
        éªŒè¯ LazyFrame çš„ Schema æ˜¯å¦ç¬¦åˆ L2 æ ‡å‡†å¥‘çº¦ã€‚
        æ— éœ€çœŸæ­£ collect() æ•°æ®ï¼Œä»…åœ¨å…ƒæ•°æ®å±‚é¢è¿›è¡Œé™æ€æ£€æŸ¥ã€‚
        """
        expected = {
            "DATE": pl.Date,
            "ASSET": [pl.Categorical, pl.Enum, pl.String],
            "CLOSE": [pl.Float32, pl.Float64],
            "IS_SUSPENDED": pl.Boolean,
            "VOLUME": [pl.Float32, pl.Float64, pl.Int64],
        }

        actual_schema = lf.schema

        for col, expected_types in expected.items():
            if col not in actual_schema:
                logger.error(f"âŒ Schema éªŒè¯å¤±è´¥: ç¼ºå¤±å…³é”®åˆ— '{col}'")
                return False

            actual_type = actual_schema[col]
            # æ”¯æŒå¤šç§å…¼å®¹ç±»å‹ï¼ˆå¦‚ Enum å’Œ String åœ¨æŸ¥è¯¢ç«¯é€šç”¨ï¼‰
            if isinstance(expected_types, list):
                if not any(actual_type == t for t in expected_types):
                    logger.error(f"âŒ ç±»å‹ä¸åŒ¹é…: '{col}' å®é™…ä¸º {actual_type}, æœŸæœ› {expected_types}")
                    return False
            else:
                if actual_type != expected_types:
                    logger.error(f"âŒ ç±»å‹ä¸åŒ¹é…: '{col}' å®é™…ä¸º {actual_type}, æœŸæœ› {expected_types}")
                    return False

        logger.info("âœ… å› å­åº“ Schema å¥‘çº¦éªŒè¯é€šè¿‡")
        return True

    def get_data_summary(self, lf: pl.LazyFrame) -> None:
        """æ‰“å°æ•°æ®æ‘˜è¦ï¼ˆä¼šè§¦å‘ä¸€æ¬¡è½»é‡è®¡ç®—ï¼‰"""
        summary = lf.select([
            pl.col("DATE").min().alias("start"),
            pl.col("DATE").max().alias("end"),
            pl.col("ASSET").n_unique().alias("assets_count"),
            pl.len().alias("total_rows")
        ]).collect()

        logger.info(f"ğŸ“Š æ•°æ®è½½å…¥æˆåŠŸ: {summary['start'][0]} ~ {summary['end'][0]} | "
                    f"æ ‡çš„æ•°é‡: {summary['assets_count'][0]} | æ€»è¡Œæ•°: {summary['total_rows'][0]}")
