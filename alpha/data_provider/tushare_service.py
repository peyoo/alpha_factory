"""
Tushare æ•°æ®åŒæ­¥æœåŠ¡ (L0-L1 æ¥å…¥å±‚)

ã€æ ¸å¿ƒç­–ç•¥ã€‘æŒ‰æ—¥æœŸå…¨å¸‚åœºæ‰¹é‡è·å–
- æ¯ä¸ªäº¤æ˜“æ—¥è°ƒç”¨ä¸€æ¬¡ API: daily(trade_date=date)
- è¿”å›è¯¥æ—¥å…¨å¸‚åœºæ•°æ® (é€šå¸¸ 4500-5000 è¡Œ)
- ç¦æ­¢æŒ‰è‚¡ç¥¨å¾ªç¯ (ts_code å‚æ•°)
- æ— æ•°æ®é‡è¶…é™é£é™©
"""
import os
import time
from loguru import logger
from datetime import datetime, date
from typing import Optional
import pandas as pd
import polars as pl

from alpha.utils.config import settings
from alpha.data_provider.cache_manager import HDF5CacheManager
from alpha.data_provider.unified_factor_builder import UnifiedFactorBuilder
from alpha.data_provider.trade_calendar_manager import TradeCalendarManager
from alpha.data_provider.stock_assets_manager import StockAssetsManager
from alpha.utils.schema import F


class DataSyncError(RuntimeError):
    """è‡´å‘½æ€§åŒæ­¥é”™è¯¯ï¼šå½“å…³é”®åˆ†ç‰‡ç¼ºå¤±æˆ–å†™å…¥å¤±è´¥æ—¶æŠ›å‡ºã€‚"""
    pass


class RateLimiter:
    """API é™æµæ§åˆ¶å™¨ï¼ˆåŸºäº Tushare å®˜æ–¹é™æµç­–ç•¥ï¼‰"""

    def __init__(self, is_vip: bool = True):
        self.is_vip = is_vip
        # VIP: 800æ¬¡/åˆ† â‰ˆ 75ms; æ™®é€š: 200æ¬¡/åˆ† â‰ˆ 300ms
        self.min_interval = 0.075 if is_vip else 0.3
        self.last_request_time = 0

    def wait(self) -> None:
        elapsed = time.time() - self.last_request_time
        if elapsed < self.min_interval:
            time.sleep(self.min_interval - elapsed)
        self.last_request_time = time.time()


class TushareDataService:
    """
    Tushare æ•°æ®åŒæ­¥æœåŠ¡ (L0-L1)

    ã€æ ¸å¿ƒæ¶æ„ã€‘
    - æ¥å…¥å±‚ï¼šPython datetime.date å¯¹è±¡ (é€šç”¨æ€§ã€å¯è¯»æ€§)
    - ç¼“å­˜å±‚ï¼šHDF5 (ä¿æŠ¤ API ç§¯åˆ†ï¼Œå†™å‰å¿…æŸ¥ is_cached)
    - è®¡ç®—å±‚ï¼šPolars (æè‡´æ€§èƒ½ï¼ŒDate æ˜ å°„ä¸º Int32)
    """

    def __init__(self):
        # 1. Token è·å–é€»è¾‘
        self.token = getattr(settings, "TUSHARE_TOKEN", None) or os.getenv("TUSHARE_TOKEN")
        if not self.token:
            raise ValueError("âŒ TUSHARE_TOKEN æœªè®¾ç½®ï¼Œè¯·åœ¨ settings æˆ–ç¯å¢ƒå˜é‡ä¸­é…ç½®")

        is_vip = settings.is_vip
        self.rate_limiter = RateLimiter(is_vip)
        self.pro = self._init_tushare()

        # 2. åˆå§‹åŒ–æ ¸å¿ƒç®¡ç†å™¨
        self.cache_manager = HDF5CacheManager(settings.RAW_DATA_DIR)
        self.calendar = TradeCalendarManager()
        self.assets_mgr = StockAssetsManager()

        # 3. åˆå§‹åŒ–å› å­æ„å»ºå™¨ (ä¿®æ­£ç‚¹ï¼šåŒ¹é…æœ€æ–°çš„ __init__ ç­¾å)
        # UnifiedFactorBuilder æœŸæœ›ä½ç½®å‚æ•°ï¼šassets_mgr, calendar_mgr
        self.factor_builder = UnifiedFactorBuilder(self.assets_mgr, self.calendar)

        logger.info(f"âœ“ TushareService åˆå§‹åŒ–å®Œæˆ (VIP={is_vip})")

    def _init_tushare(self):
        import tushare as ts
        return ts.pro_api(self.token)

    # ---------------------------------------------------------------------
    # æ ¸å¿ƒåŒæ­¥æµç¨‹
    # ---------------------------------------------------------------------

    def sync_data(self, start_date: str, end_date: Optional[str] = None) -> None:
        """
        å…¨é‡åŒæ­¥ä¸»å…¥å£ï¼šæŒ‰å¤©æ‰“åŒ…åŒæ­¥æ‰€æœ‰åˆ†ç‰‡ï¼ˆå·²é€‚é…é•¿è¿æ¥ä¼˜åŒ–ï¼‰
        """
        # 1. å‰ç½®å…ƒæ•°æ®åŒæ­¥
        try:
            self.calendar.sync_from_tushare()
            self.assets_mgr.sync_from_tushare()
        except Exception as e:
            logger.warning(f"å…ƒæ•°æ®åŒæ­¥å‘Šè­¦: {e}")

        # 2. ç¡®å®š end_dateï¼šå¦‚æœä¸º Noneï¼Œæ™ºèƒ½æŸ¥æ‰¾æœ€æ–°å¯ç”¨æ•°æ®
        if end_date is None:
            end_date = self._find_latest_available_date()
            logger.info(f"â° end_date è‡ªåŠ¨è®¾ç½®ä¸º: {end_date} (daily_basic æœ€æ–°å¯ç”¨æ•°æ®)")

        # 3. è·å–äº¤æ˜“æ—¥åˆ—è¡¨
        start_dt = datetime.strptime(start_date, "%Y%m%d").date()
        end_dt = datetime.strptime(end_date, "%Y%m%d").date()
        trade_days = self.calendar.get_trade_days(start_dt, end_dt)

        if not trade_days:
            logger.warning(f"âš ï¸ {start_date} ~ {end_date} ä¹‹é—´æ— äº¤æ˜“æ—¥")
            return

        total = len(trade_days)
        logger.info(f"ğŸš€ å¼€å§‹åŒæ­¥ä»»åŠ¡ï¼Œå…±è®¡ {total} ä¸ªäº¤æ˜“æ—¥...")

        # 4. ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨ try...finally ç»´æŠ¤ HDF5 é•¿è¿æ¥
        try:
            for i, current_date in enumerate(trade_days, 1):
                # æ­¤æ—¶å†…éƒ¨è°ƒç”¨çš„ is_cached å’Œ save_to_hdf5 ä¼šè‡ªåŠ¨å¤ç”¨å·²æ‰“å¼€çš„å¥æŸ„
                self._sync_single_day_bundle(current_date, i, total)

            logger.success("âœ¨ æ‰€æœ‰æ•°æ®åˆ†ç‰‡åŒæ­¥å·²å®Œæˆå¹¶åˆ·å…¥ç£ç›˜")

        except Exception as e:
            logger.error(f"âŒ åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
            raise  # å‘ä¸ŠæŠ›å‡ºä»¥é˜²åç»­å› å­æ„å»ºåœ¨é”™è¯¯åŸºç¡€ä¸Šè¿è¡Œ

        finally:
            # ğŸ’¡ æ— è®ºä»»åŠ¡æˆåŠŸè¿˜æ˜¯æŠ¥é”™ä¸­æ–­ï¼Œå¿…é¡»æ˜¾å¼é‡Šæ”¾æ–‡ä»¶å¥æŸ„
            self.cache_manager.close_all()

        # 4. åŒæ­¥å®Œæˆåè§¦å‘ L2 æ„å»º
        logger.info("âš™ï¸ å¯åŠ¨å¹´åº¦ Parquet å› å­åº“æ„å»º...")
        self.factor_builder.build_unified_factors(start_dt, end_dt)

    def _sync_single_day_bundle(self, trade_date: date, idx: int, total: int) -> None:
        date_str = trade_date.strftime("%Y%m%d")

        # 1. å®šä¹‰æ ‡å‡†ä»»åŠ¡è¡¨ (æ•°æ®æº, APIå‡½æ•°, é¢„æœŸçš„ Schema)
        # ç»Ÿä¸€ä½¿ç”¨ dict å­˜å‚¨åˆ—åå’Œ Dtypeï¼Œæ—¢èƒ½ç”¨äº fields å‚æ•°ï¼Œä¹Ÿèƒ½ç”¨äº astype
        tasks = [
            ("daily", self.pro.daily, {
                "ts_code": "string",
                "open": "float32",
                "high": "float32",
                "low": "float32",
                "close": "float32",
                "vol": "float32",
                "amount": "float64"
            }),
            ("adj_factor", self.pro.adj_factor, {
                "ts_code": "string",
                "adj_factor": "float32"
            }),
            ("daily_basic", self.pro.daily_basic, {
                "ts_code": "string",
                "turnover_rate": "float32",
                "pe": "float32",
                "pb": "float32",
                "ps": "float32",
                "total_mv": "float64",
                "circ_mv": "float64"
            }),
            ("stk_limit", self.pro.stk_limit, {
                "ts_code": "string",
                "up_limit": "float32",
                "down_limit": "float32"
            }),
            ("suspend_d", self.pro.suspend_d, {
                "ts_code": "string",
                "suspend_type": "string"
            }),
            ("st", self.pro.stock_st, {
                "ts_code": "string",
                "is_st": "string"
            }),
        ]

        for source, api_func, fields_schema in tasks:
            if self.cache_manager.is_cached(source, trade_date):
                continue

            try:
                self.rate_limiter.wait()

                # ğŸ’¡ 1. ç²¾å‡†è·å–ï¼šåªæ‹¿ fields_schema ä¸­å®šä¹‰çš„ä¸šåŠ¡å­—æ®µ
                fetch_fields = list(fields_schema.keys())
                df = api_func(trade_date=date_str, fields=fetch_fields)

                if df is None or df.empty:
                    continue

                # ğŸ’¡ 2. å¼ºè½¬ç±»å‹ï¼šä»…ä¸ºå…¼å®¹ Fixed æ¨¡å¼å’Œå†…å­˜ä¼˜åŒ–
                # æ­¤æ—¶ df å·²ç»æ²¡æœ‰å†—ä½™æ—¥æœŸåˆ—äº†
                for col, dtype in fields_schema.items():
                    if col in df.columns:
                        if dtype == "string":
                            df[col] = df[col].fillna("").astype(str).astype("S12")
                        else:
                            df[col] = pd.to_numeric(df[col], errors='coerce').astype(dtype)

                # ğŸ’¡ 3. ç›´æ¥è½ç›˜
                self.cache_manager.save_to_hdf5(source, trade_date, df)
                logger.info(f"[{idx}/{total}] âœ“ å·²æŒä¹…åŒ–: {source} ({date_str})")

            except Exception as e:
                logger.error(f"âŒ {date_str} {source} å¼‚å¸¸: {e}")
                raise DataSyncError(f"API ä¸­æ–­: {source}")

    def _find_latest_available_date(self, lookback_days: int = 10) -> str:
        """
        æ™ºèƒ½æŸ¥æ‰¾ Tushare ä¸Šæœ€æ–°å¯ç”¨æ•°æ®çš„äº¤æ˜“æ—¥

        ã€ä½¿ç”¨ daily_basic æ¥å£åˆ¤æ–­æ•°æ®å¯ç”¨æ€§ã€‘
        daily_basic åŒ…å« PEã€PBã€PS ç­‰ä¼°å€¼æ•°æ®ï¼Œæ•°æ®å®Œæ•´æ€§æ›´å¥½ã€‚
        Tushare ç½‘ç«™ä¸Šçš„æ•°æ®é€šå¸¸æœ‰ 1-2 ä¸ªäº¤æ˜“æ—¥çš„å»¶è¿Ÿã€‚

        å‚æ•°:
            lookback_days: æœ€å¤šå¾€å‰æŸ¥æ‰¾å¤šå°‘ä¸ªäº¤æ˜“æ—¥ (é»˜è®¤ 10)

        è¿”å›:
            æœ‰æ•°æ®çš„æœ€æ–°äº¤æ˜“æ—¥ 'YYYYMMDD' æ ¼å¼
        """
        today = date.today()

        # è·å–è¿‡å»çš„äº¤æ˜“æ—¥åˆ—è¡¨
        lookback_start = today - pd.Timedelta(days=lookback_days * 2)
        trade_days_back = self.calendar.get_trade_days(lookback_start, today)

        if not trade_days_back:
            logger.warning(f"âš ï¸ æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¿”å›ä»Šå¤©: {today.strftime('%Y%m%d')}")
            return today.strftime("%Y%m%d")

        # åå‘éå†ï¼ˆä»æœ€è¿‘å¾€å‰ï¼‰ï¼Œæœ€å¤šæŸ¥æ‰¾ lookback_days ä¸ª
        checked_count = 0
        for check_date in reversed(trade_days_back):
            if checked_count >= lookback_days:
                break

            date_str = check_date.strftime("%Y%m%d")
            checked_count += 1

            try:
                # ä½¿ç”¨ daily_basic æ¥å£ï¼Œåªè·å– 1 æ¡è®°å½•æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
                self.rate_limiter.wait()
                df = self.pro.daily_basic(trade_date=date_str, limit=1)

                # å¦‚æœè¿”å›ä¸ä¸ºç©ºï¼Œè¯´æ˜è¯¥æ—¥æœ‰æ•°æ®
                if df is not None and not df.empty:
                    logger.info(f"âœ“ æ‰¾åˆ°æœ€æ–°å¯ç”¨æ•°æ® (daily_basic): {date_str} (æ£€æŸ¥äº† {checked_count} ä¸ªäº¤æ˜“æ—¥)")
                    return date_str
                else:
                    logger.debug(f"â­ï¸  {date_str} æ— æ•°æ®ï¼Œç»§ç»­æŸ¥æ‰¾")

            except Exception as e:
                logger.debug(f"âŒ æ£€æŸ¥ {date_str} æ—¶å¼‚å¸¸: {e}ï¼Œç»§ç»­æŸ¥æ‰¾")
                continue

        # å¦‚æœæ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•°æ®çš„æ—¥æœŸï¼Œè¿”å›ä»Šå¤©
        logger.warning(
            f"âš ï¸ å‘å‰æŸ¥æ‰¾ {lookback_days} ä¸ªäº¤æ˜“æ—¥éƒ½æ— æ•°æ®ï¼Œä½¿ç”¨ä»Šå¤©ä½œä¸º end_date: {today.strftime('%Y%m%d')}")
        return today.strftime("%Y%m%d")

    # ---------------------------------------------------------------------
    # å¢é‡æ›´æ–°é€»è¾‘
    # ---------------------------------------------------------------------

    def daily_update(self) -> None:
        """æ—¥é¢‘è‡ªåŠ¨å¢é‡åŒæ­¥"""
        # ä» L2 ä»“åº“æ¢æµ‹æœ€æ–°æ—¥æœŸ
        _, last_date_str = self._get_latest_date_from_warehouse()
        if not last_date_str:
            logger.error("æ— æ³•è·å–ä»“åº“æ—¥æœŸï¼Œè¯·å…ˆè¿›è¡Œå…¨é‡åŒæ­¥")
            return

        last_date = datetime.strptime(last_date_str, "%Y%m%d").date()
        next_date = self.calendar.offset(last_date, 1)

        if next_date > date.today():
            logger.info("âœ… æ•°æ®å·²æ˜¯æœ€æ–°")
            return

        self.sync_data(next_date.strftime("%Y%m%d"), end_date=None)

    def _get_latest_date_from_warehouse(self) -> tuple[Optional[int], Optional[str]]:
        """åˆ©ç”¨ Polars å¿«é€Ÿæ¢æµ‹ Parquet ä»“åº“çš„æœ€å¤§æ—¥æœŸ"""
        path = self.factor_builder.warehouse_dir / "unified_factors/*.parquet"
        try:
            # æè‡´æ€§èƒ½ï¼šåªæ‰«æä¸åŠ è½½ï¼Œè·å–æœ€å¤§å€¼
            # æ³¨æ„ï¼šç»Ÿä¸€å› å­åº“çš„æ—¥æœŸåˆ—æ˜¯ DATEï¼ˆè€Œé trade_dateï¼‰
            max_date = pl.scan_parquet(str(path)).select(pl.col(F.DATE).max()).collect().item()
            if max_date:
                if isinstance(max_date, pl.Date):
                    max_date = max_date.as_py()
                return None, max_date.strftime("%Y%m%d")
        except Exception as e:
            logger.debug(f"è·å–ä»“åº“æœ€å¤§æ—¥æœŸå¤±è´¥: {e}")
        return None, None
